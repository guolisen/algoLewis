[TOC]



# 预训练和微调

### 一、什么是模型预训练

**模型预训练**是指在**大规模通用数据集**上，对基础模型（如 Transformer、CNN 等）进行训练，让模型学习到数据中的通用特征和规律（例如语言模型学习语法、语义，视觉模型学习边缘、纹理）的过程。这个阶段的训练目标通常是**通用任务**，而非具体业务任务，训练后的模型被称为**预训练模型**（如 BERT、GPT、ResNet50）。

#### 核心特点

1. **数据规模大**：使用海量无标注或弱标注数据（例如互联网文本、ImageNet 图像）。
2. **任务通用性强**：例如语言模型的 “掩码语言建模（MLM）”“下一句预测（NSP）”，视觉模型的 “图像分类预训练”。
3. **模型参数共享**：预训练好的模型参数可作为下游任务的初始化权重，避免从零开始训练。

------

### 二、为什么要预训练

预训练的核心价值是**解决小样本场景下的模型训练难题**，同时大幅提升模型性能和训练效率，具体原因如下：

1. **降低数据依赖**下游任务（如特定领域的文本分类、目标检测）往往只有少量标注数据，从零训练模型容易过拟合。预训练模型通过海量数据学到的通用特征，可迁移到下游任务，用少量数据就能达到较好效果。
2. **提升模型泛化能力**预训练过程中，模型接触到多样化的数据集，能学习到跨领域的通用规律（例如语言模型能理解不同语境下的语义），避免模型局限于单一任务的 “偏置”。
3. **大幅减少训练成本**大型模型（如 GPT-3、ViT）的参数量可达百亿甚至千亿级别，从零训练需要巨大的算力和时间成本。预训练模型提供了 “现成的权重初始化”，下游任务只需微调部分参数，训练效率提升一个数量级。
4. **统一模型架构**预训练模型（如 Transformer）可作为通用的基础架构，适配不同下游任务（文本生成、图像分割、语音识别），无需为每个任务设计专用模型。

------

### 三、预训练与微调的核心区别

预训练和微调是**模型训练的两个连续阶段**，目标、数据、任务和参数更新策略完全不同，具体对比如下：

| **维度**     | **预训练**                                  | **微调（Fine-tuning）**                                      |
| ------------ | ------------------------------------------- | ------------------------------------------------------------ |
| **目标**     | 学习通用特征和规律，得到基础预训练模型      | 适配具体下游任务，让模型在特定任务上达到最优                 |
| **数据**     | 海量通用无标注 / 弱标注数据                 | 少量特定领域**标注数据**（如医疗文本、工业质检图像）         |
| **任务**     | 通用任务（如 MLM、图像分类预训练）          | 具体任务（如文本分类、目标检测、机器翻译）                   |
| **模型参数** | 更新全部或大部分参数（从头训练或迭代优化）  | 基于预训练权重，**更新部分或全部参数**（通常冻结底层特征提取层，只更新顶层任务层） |
| **算力成本** | 极高（需要大规模 GPU/TPU 集群，训练周期长） | 较低（仅微调部分参数，训练周期短）                           |
| **适用场景** | 模型研发阶段（如大厂训练通用大模型）        | 业务落地阶段（如企业将预训练模型适配自身场景）               |

#### 关键补充：微调的两种常见策略

1. **全参数微调**：更新预训练模型的所有参数，适合下游任务数据充足的场景。
2. **参数高效微调（PEFT）**：只更新少量新增参数（如 Adapter、LoRA），冻结预训练模型的大部分权重，适合小样本场景和低算力设备。

------

### 总结

- **预训练**是 “打基础”：用海量数据训练通用模型，学习通用特征。
- **微调**是 “做适配”：用少量标注数据调整模型，适配具体任务。







# 指令微调（SFT）：让大模型听懂人话的关键技术

## 一、一句话概括

**指令微调**就是**教大模型如何理解并执行人类指令**，让原本只是"学了一堆知识"的模型变成"能按要求干活"的助手。

**类比**：

- **基础大模型**：一个读过万卷书但不会聊天的学者
- **指令微调后**：一个能回答你问题、帮你写东西的贴心助手

------

## 二、从基础模型到指令模型的转变

### **微调前 vs 微调后对比**

| 场景                               | 基础模型（微调前）                                 | 指令微调后                   |
| :--------------------------------- | :------------------------------------------------- | :--------------------------- |
| **你问**：写一首关于春天的诗       | 继续训练文本："春天是..." （它以为你在给文章开头） | 按要求生成一首完整的诗 ✅     |
| **你问**：用Python计算斐波那契数列 | 解释斐波那契数列定义 （只回答问题，不写代码）      | 直接给出可运行的Python代码 ✅ |
| **你问**：总结下面文章...          | 继续往下写文章 （不理解"总结"指令）                | 生成准确的摘要 ✅             |

------

## 三、为什么需要指令微调？

### **问题：基础大模型不会"听指挥"**

python

```
# 基础模型（预训练后）的表现：
输入: "写一封辞职信"
输出: "写一封辞职信是一件需要谨慎考虑的事情。首先，你需要..." 
# 它在解释"如何写辞职信"，而不是真的写！

输入: "把'你好'翻译成英文"
输出: "'你好'在中文中是问候语，对应英文的'hello'..."
# 它在解释翻译，而不是直接翻译！

输入: "分类情感：今天天气真好"
输出: "今天天气真好，阳光明媚，适合出游..."
# 它在续写，而不是分类！
```



### **解决方案：指令微调**

教会模型识别这些"指令词"：

- `写...` → 生成内容
- `翻译...` → 进行翻译
- `总结...` → 进行摘要
- `分类...` → 进行分类

------

## 四、指令微调具体怎么做？

### **1. 数据格式：指令-回复对**

json

```
[
  {
    "instruction": "写一首关于春天的五言绝句",
    "input": "",
    "output": "春眠不觉晓，处处闻啼鸟。夜来风雨声，花落知多少。"
  },
  {
    "instruction": "用Python计算圆的面积",
    "input": "半径=5",
    "output": "import math\nradius = 5\narea = math.pi * radius ** 2\nprint(f'面积为: {area:.2f}')"
  },
  {
    "instruction": "总结下面文章",
    "input": "人工智能是当今最热门的技术领域...（长文章）",
    "output": "本文介绍了人工智能的发展现状、应用场景和未来趋势..."
  }
]
```



### **2. 训练过程简化版**

python

```
# 伪代码：指令微调的核心
def instruction_finetuning(model, instruction_data):
    for example in instruction_data:
        # 构造输入：指令 + 输入内容
        prompt = f"指令：{example['instruction']}\n输入：{example['input']}"
        
        # 期望输出：模型应该给出的回复
        expected_output = example['output']
        
        # 训练模型：让模型学会"看到指令，生成对应回复"
        loss = train_step(model, prompt, expected_output)
        
    return model  # 现在模型懂得按指令干活了
```



------

## 五、实际例子：看模型如何变化

### **例1：写邮件**

**指令**："帮我写封邮件请假，理由生病，请3天假"

**基础模型可能输出**：

text

```
请假邮件需要注意格式。首先要有称呼，比如"尊敬的领导"，
然后说明请假原因和时长，最后要有署名和日期。
生病请假最好附上医生证明...
```



❌ **它在教你怎么写，而不是帮你写**

**指令微调后输出**：

text

```
主题：请假申请

尊敬的领导：

我因身体不适，需要请假3天（从X月X日至X月X日）。
医院诊断为重感冒，医生建议休息。工作已安排妥当，不会影响项目进度。

恳请批准，谢谢！

此致
敬礼！

[你的名字]
[日期]
```



✅ **它直接写出了可用的邮件**

------

### **例2：多轮对话**

**对话历史**：

- 用户："推荐一部科幻电影"
- 助手："《星际穿越》不错，讲述太空探险的故事"

**新指令**："再推荐一部，要近年的"

**基础模型可能输出**：

text

```
《星际穿越》是2014年的电影，导演诺兰...
```



❌ **它继续讨论上一部电影，没理解"再推荐一部"**

**指令微调后输出**：

text

```
近年的话可以看《沙丘》（2021），视觉效果很棒，改编自经典科幻小说。
```



✅ **它理解了这是新请求，推荐了另一部电影**

------

## 六、指令微调的技术细节

### **常用数据格式模板**

python

```
# 1. Alpaca格式（斯坦福）
{
  "instruction": "写一个请假条",
  "input": "理由：参加婚礼，时间：2天",
  "output": "尊敬的领导：..."
}

# 2. ShareGPT格式（对话）
[
  {"from": "human", "value": "用JavaScript写个计数器"},
  {"from": "gpt", "value": "以下是示例代码：\n```javascript\nlet count = 0;\nfunction increment() {\n  count++;\n  console.log(count);\n}\n```"}
]

# 3. 系统提示词 + 对话
{
  "system": "你是一个编程助手",
  "conversations": [
    {"role": "user", "content": "Python里怎么读文件"},
    {"role": "assistant", "content": "用open函数：\n```python\nwith open('file.txt', 'r') as f:\n    content = f.read()\n```"}
  ]
}
```



### **训练技巧**

python

```
# 关键：只计算回复部分的loss
def calculate_loss(model_output, target):
    """
    输入: "指令：写诗\n输入：关于春天"
    目标: "春眠不觉晓..."
    
    只让模型对"春眠不觉晓..."这部分负责，
    不对"指令：写诗\n输入：关于春天"计算loss
    """
    # 找到指令部分结束的位置
    instruction_end = find_instruction_end(model_output)
    
    # 只计算回复部分的损失
    reply_tokens = target[instruction_end:]
    loss = compute_loss_for_tokens(reply_tokens)
    
    return loss
```



------

## 七、指令微调 vs 其他微调

### **对比表**

| 微调类型         | 目的           | 数据示例       | 效果                     |
| :--------------- | :------------- | :------------- | :----------------------- |
| **指令微调**     | 让模型听懂指令 | 指令-回复对    | 变成"助手"，能按指令干活 |
| **继续预训练**   | 补充专业知识   | 专业文档、代码 | 增加知识，但不会对话     |
| **奖励模型训练** | 对齐人类偏好   | 好坏回复对比   | 让回答更符合人类喜好     |
| **LoRA/QLoRA**   | 高效微调方法   | 各种任务数据   | 用较少资源微调大模型     |

### **关系图**：

text

```
基础预训练模型（知识库）
        ↓
   指令微调（SFT） ← 让模型"会对话"
        ↓
   奖励模型训练（RLHF） ← 让对话"质量更高"
        ↓
   最终对话模型（如ChatGPT）
```



# 数据预处理

你现在关注的是针对 LLaMA3 模型微调时的训练数据预处理技巧，这是让微调效果最大化的核心环节之一。LLaMA3 作为大语言模型（LLM），其数据预处理有通用 LLM 的共性，也有适配其架构和训练范式的专属技巧，我会结合 LLaMA3 的特点，从**数据清洗、格式标准化、文本处理、增强与适配、效率优化**五个维度拆解实用技巧：

### 一、核心前提：先明确 LLaMA3 的适配规则

LLaMA3 的输入有明确约束，预处理前需先对齐：

- 文本最大长度：7B/8B 版本默认上下文窗口为 8192 tokens（部分微调版支持更长），预处理需严格控制长度；
- 分词器：使用 Meta 官方的 LLaMA3 Tokenizer（基于 SentencePiece，字节级 BPE），需用原生分词器处理，避免自定义分词导致 token 不匹配；
- 指令格式：LLaMA3 对指令微调（SFT）的格式敏感，推荐遵循 Meta 官方的`<|begin_of_text|>` `<|end_of_text|>`等特殊 token 规范。

### 二、针对 LLaMA3 微调的核心预处理技巧

#### 1. 数据清洗：过滤 “脏数据”，避免模型学错规律

这是预处理的第一步，直接决定微调下限，重点针对 LLaMA3 易受影响的噪声类型：

- **过滤低质量文本**：
    - 移除乱码、特殊符号堆砌（如`@￥%……&*`）、无意义重复文本（如 “啊啊啊”“1111”）；
    - 过滤短文本（如少于 10 个有效 token），避免模型学习碎片化信息；
    - 对中英文混合数据，若任务是单语种（如纯中文），需移除无关语种文本（LLaMA3 原生以英文为主，中文微调需确保中文文本纯净）。
- **去重处理**：
    - 按文本内容去重（可通过 SimHash、MD5 哈希或余弦相似度），避免重复数据占比过高导致模型过拟合；
    - 对指令 - 回复对（SFT 数据），需按 “指令 + 回复” 整体去重，而非单独对指令 / 回复去重。
- **修正逻辑错误**：
    - 对指令微调数据，检查 “指令 - 回复” 的匹配性（如指令问 “计算 1+1”，回复不能是 “苹果”）；
    - 移除矛盾、错误的回复（如事实性错误、语法混乱的回复）。

#### 2. 格式标准化：对齐 LLaMA3 的指令微调范式

LLaMA3 的 SFT 效果高度依赖统一的文本格式，Meta 推荐的格式如下（以对话式微调为例），预处理需严格对齐：

```python
# LLaMA3官方推荐的指令微调格式（单轮对话）
def format_llama3_prompt(instruction, response):
    system_prompt = "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n你是一个有用的助手，严格按照用户指令回答问题。<|eot_id|>"
    user_prompt = f"<|start_header_id|>user<|end_header_id|>\n{instruction}<|eot_id|>"
    assistant_prompt = f"<|start_header_id|>assistant<|end_header_id|>\n{response}<|eot_id|><|end_of_text|>"
    return system_prompt + user_prompt + assistant_prompt

# 示例：格式化单条数据
instruction = "解释什么是模型预训练"
response = "模型预训练是在大规模通用数据集上训练基础模型，让模型学习通用特征的过程..."
formatted_text = format_llama3_prompt(instruction, response)
```

- **关键技巧**：
    - 必须使用 LLaMA3 的特殊 token（`<|begin_of_text|>` `<|start_header_id|>` `<|eot_id|>`等），这些 token 是模型预训练时已学习的，自定义 token 会导致模型无法识别；
    - 多轮对话需按轮次嵌套格式（user→assistant→user→assistant），每轮都需加对应的 header_id 和 eot_id；
    - 避免格式混用（如部分数据加 system prompt，部分不加），格式统一是 LLM 微调的核心原则。

#### 3. 文本处理：适配 LLaMA3 的 Tokenizer 和长度约束

LLaMA3 的 Tokenizer 是 SentencePiece，需针对性处理：

- **Tokenizer 适配**：
    - 直接使用`transformers.LlamaTokenizerFast`加载 LLaMA3 的分词器，禁用自定义分词（如 jieba），避免 token 拆分不一致；
    - 处理中文时，需确保 Tokenizer 能正确切分中文（可结合 LLaMA3 的中文增强版 Tokenizer，或先对中文做基础分词但不拆分字符）；
    - 保留文本中的自然标点（如句号、逗号），LLaMA3 的 Tokenizer 对标点的处理影响语义理解，勿盲目移除。
- **长度控制**：
    - 按 LLaMA3 的上下文窗口（8192 tokens）截断文本，**优先保留核心信息**：
        - 指令微调数据：优先保留 “指令” 完整，再截断过长的 “回复”；
        - 续写类数据：从文本末尾截断，避免破坏开头的语义；
    - 避免硬截断导致语义断裂：可按句子边界（如句号、换行）截断，而非直接按 token 数切分；
    - 对超长文本（如超过 8192 tokens），可采用 “分段 + 标注” 的方式，或使用 LLaMA3 的长上下文版本（如 LLaMA3-70B-Instruct-128K）。
- **特殊字符处理**：
    - 统一换行符（如全部转为`\n`）、空格（移除连续多个空格，保留单个空格）；
    - 对代码类数据（如 LLaMA3 微调代码生成任务），保留代码的缩进、换行、注释格式，Tokenizer 能识别这些格式的语义价值。

#### 4. 数据增强：提升微调泛化性（适配 LLaMA3 的小样本场景）

LLaMA3 微调通常是小样本场景，数据增强能有效提升鲁棒性，核心技巧：

- **指令多样化**：
    - 对同一任务的核心需求，生成不同表述的指令（如 “写一篇关于预训练的短文”→“请用 300 字解释预训练的核心价值”→“简述预训练的定义和作用”）；
    - 避免指令表述过于单一，导致模型只适配特定话术。
- **回复润色（不改变核心语义）**：
    - 对回复文本做同义改写（如替换同义词、调整句式），但需保持核心信息准确；
    - 对长回复拆分 / 合并（如将长句拆为短句，或短句合并为长句），提升模型对不同长度回复的适配能力。
- **噪声注入（适度）**：
    - 少量添加自然噪声（如偶尔的错别字、口语化表达），模拟真实用户输入场景；
    - 注意：LLaMA3 对噪声敏感，噪声比例需控制在 5% 以内，避免模型学错。
- **数据采样平衡**：
    - 若微调数据包含多类任务（如问答、总结、创作），需按任务重要性平衡采样比例，避免某类数据占比过高导致模型偏科；
    - 对低频但重要的任务（如专业领域问答），可做过采样。

#### 5. 效率与适配优化（针对 LLaMA3 微调的工程技巧）

- **Token 化提前处理**：
    - 预处理阶段完成所有文本的 token 化，并保存为二进制文件（如.pkl、.arrow），避免微调时重复 token 化，提升训练速度；
    - 使用`datasets`库的`map`函数批量处理，结合多进程加速。
- **标签掩码（Label Masking）**：
    - 微调时仅对 “回复部分” 计算损失，对 “指令部分” 做掩码（LLaMA3 的 SFT 核心）；
    - 示例：格式化后的文本中，`<|start_header_id|>assistant<|end_header_id|>`后的内容为目标标签，其余部分掩码。
- **批次适配**：
    - 预处理时按 token 长度分组（如短文本组、长文本组），避免批次内长度差异过大导致 padding 过多，浪费计算资源；
    - 对 LLaMA3，推荐使用动态 padding（仅 padding 到批次内最长文本），而非固定长度 padding。
- **数据格式转换**：
    - 最终转换为 LLaMA3 微调框架适配的格式（如 Hugging Face 的`Dataset`格式、JSONL 格式），确保字段名统一（如`instruction`、`response`、`text`）。

### 三、LLaMA3 微调数据预处理的完整流程示例



```python
import re
from datasets import Dataset
from transformers import LlamaTokenizerFast

# 1. 加载LLaMA3分词器
tokenizer = LlamaTokenizerFast.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct")
tokenizer.pad_token = tokenizer.eos_token  # LLaMA3默认无pad_token，需手动指定
MAX_LENGTH = 8192

# 2. 数据清洗函数
def clean_text(text):
    # 移除乱码和特殊符号
    text = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9\s，。！？；：""''()（）【】]", "", text)
    # 移除连续重复字符
    text = re.sub(r"(.)\1{3,}", r"\1", text)
    # 移除多余空格和换行
    text = re.sub(r"\s+", " ", text).strip()
    return text

# 3. 格式标准化函数
def format_llama3_text(example):
    # 清洗指令和回复
    instruction = clean_text(example["instruction"])
    response = clean_text(example["response"])
    
    # LLaMA3官方格式
    system_prompt = "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n你是一个专业的AI助手，准确回答用户问题。<|eot_id|>"
    user_prompt = f"<|start_header_id|>user<|end_header_id|>\n{instruction}<|eot_id|>"
    assistant_prompt = f"<|start_header_id|>assistant<|end_header_id|>\n{response}<|eot_id|><|end_of_text|>"
    
    full_text = system_prompt + user_prompt + assistant_prompt
    
    # 4. 长度控制：token化后截断
    tokens = tokenizer(full_text, truncation=True, max_length=MAX_LENGTH, return_tensors="pt")
    example["input_ids"] = tokens["input_ids"][0].tolist()
    example["attention_mask"] = tokens["attention_mask"][0].tolist()
    return example

# 5. 加载原始数据并预处理
raw_data = [
    {"instruction": "解释LLaMA3的预训练方式", "response": "LLaMA3采用自回归语言建模的预训练方式，基于海量文本数据学习语义和生成能力..."},
    {"instruction": "LLaMA3微调时如何处理长文本？", "response": "LLaMA3默认上下文窗口为8192 tokens，微调时可按句子边界截断长文本，或使用长上下文版本..."}
]
dataset = Dataset.from_list(raw_data)
processed_dataset = dataset.map(format_llama3_text, num_proc=4)  # 多进程加速

# 6. 保存预处理后的数据
processed_dataset.save_to_disk("./llama3_finetune_data")
```

### 总结

针对 LLaMA3 微调的训练数据预处理，核心关键点：

1. **格式对齐**：严格遵循 LLaMA3 的官方指令格式和特殊 token 规范，这是微调效果的基础；
2. **清洗优先**：过滤低质量、重复、逻辑错误的数据，避免模型学错规律；
3. **适配特性**：结合 LLaMA3 的 Tokenizer 和 8192 token 长度约束，做好文本切分和 token 化；
4. **效率优化**：提前完成 token 化、动态 padding、按长度分组，提升微调训练效率。

这些技巧的核心目标是让预处理后的数据 “既符合 LLaMA3 的输入规则，又能精准匹配你的微调任务”，避免因数据问题导致微调效果差。如果需要针对具体场景（如中文 LLaMA3 微调、多轮对话微调）的细化技巧，可以告诉我。

**举一个处理过的训练数据的例子**

这里提供一个完整的、适配 LLaMA3 指令微调的 “原始数据→预处理→训练就绪数据” 的端到端示例，包含单轮与多轮对话两种常见场景，严格遵循 LLaMA3 官方特殊 token 与格式规范。

------

### 一、原始数据（未处理）

假设我们要做 “分布式存储系统问答” 的微调，原始数据为 JSON 格式，包含指令、上下文（可选）和回复，存在少量格式不规范和冗余信息：

```json
// 单轮对话原始数据（含冗余空格和标点混乱）
{
  "instruction": " 解释Kubernetes CRD在企业级存储系统（如PowerStore）中的作用？  ",
  "context": "PowerStore是戴尔的企业级统一存储系统，支持块、文件、对象存储。",
  "response": "Kubernetes CRD(自定义资源定义)可以将PowerStore的存储资源（如卷、快照）封装为K8s原生资源！管理员通过kubectl直接管理，不用调用存储API，简化集成~"
}

// 多轮对话原始数据（无格式标记，角色不明确）
{
  "conversations": [
    {"role": "user", "content": "PowerStore如何与K8s集成？"},
    {"role": "assistant", "content": "通过CSI驱动+CRD，CSI负责卷的创建/挂载，CRD扩展自定义存储策略。"},
    {"role": "user", "content": "CRD比传统API有什么优势？"},
    {"role": "assistant", "content": "原生K8s生态兼容、声明式配置、支持RBAC权限控制，运维更高效。"}
  ]
}
```

------

### 二、预处理步骤与核心逻辑

1. 清洗：去冗余空格、统一标点、修正表述；
2. 格式对齐：添加 LLaMA3 官方特殊 token（`<|begin_of_text|>` `<|start_header_id|>` `<|eot_id|>`等）；
3. Token 化：用 LLaMA3 Tokenizer 处理，控制长度≤8192 tokens；
4. 标签掩码：仅对 assistant 回复部分计算损失，指令 / 上下文部分掩码。

------

### 三、预处理后训练数据（最终训练就绪格式）

#### 1. 单轮对话处理后示例（含完整格式与 token 化结果）

```json
{
  "text": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n你是企业级存储系统专家，回答需专业且易懂。<|eot_id|><|start_header_id|>user<|end_header_id|>\n解释Kubernetes CRD在企业级存储系统（如PowerStore）中的作用？\n上下文：PowerStore是戴尔的企业级统一存储系统，支持块、文件、对象存储。<|eot_id|><|start_header_id|>assistant<|end_header_id|>\nKubernetes CRD（自定义资源定义）可以将PowerStore的存储资源（如卷、快照）封装为Kubernetes原生资源。管理员通过kubectl直接管理，无需调用存储API，大幅简化PowerStore与K8s的集成流程。<|eot_id|><|end_of_text|>",
  "input_ids": [128000, 128006, 9125, 128007, ..., 128009],  // Tokenizer生成的token ID列表
  "attention_mask": [1, 1, 1, ..., 0],  // 有效token为1，padding为0
  "labels": [-100, -100, ..., 3456, 5678, ...]  // 仅assistant回复部分为有效token ID，其余为-100（掩码）
}
```

#### 2. 多轮对话处理后示例（含完整格式）

```json
{
  "text": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n你是企业级存储系统专家，回答需专业且易懂。<|eot_id|><|start_header_id|>user<|end_header_id|>\nPowerStore如何与K8s集成？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n通过CSI驱动+CRD，CSI负责卷的创建/挂载，CRD扩展自定义存储策略。<|eot_id|><|start_header_id|>user<|end_header_id|>\nCRD比传统API有什么优势？<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n原生K8s生态兼容、声明式配置、支持RBAC权限控制，运维更高效。<|eot_id|><|end_of_text|>",
  "input_ids": [128000, 128006, 9125, ..., 128009],
  "attention_mask": [1, 1, ..., 0],
  "labels": [-100, -100, ..., 4567, 8901, ...]
}
```

------

### 四、预处理代码片段（关键实现）

```python
from transformers import LlamaTokenizerFast
from datasets import Dataset

tokenizer = LlamaTokenizerFast.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct")
tokenizer.pad_token = tokenizer.eos_token
MAX_LENGTH = 8192

# 单轮数据预处理函数
def preprocess_single_turn(example):
    # 1. 清洗
    instruction = example["instruction"].strip().replace("  ", " ").replace("！", "。").replace("~", "。")
    context = example.get("context", "").strip()
    response = example["response"].strip().replace("(自定义资源定义)", "（自定义资源定义）")
    
    # 2. 格式对齐（LLaMA3官方规范）
    system_prompt = "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n你是企业级存储系统专家，回答需专业且易懂。<|eot_id|>"
    user_prompt = f"<|start_header_id|>user<|end_header_id|>\n{instruction}\n上下文：{context}<|eot_id|>"
    assistant_prompt = f"<|start_header_id|>assistant<|end_header_id|>\n{response}<|eot_id|><|end_of_text|>"
    full_text = system_prompt + user_prompt + assistant_prompt
    
    # 3. Token化+截断
    tokens = tokenizer(full_text, truncation=True, max_length=MAX_LENGTH, return_tensors="pt")
    input_ids = tokens["input_ids"][0].tolist()
    attention_mask = tokens["attention_mask"][0].tolist()
    
    # 4. 标签掩码（仅assistant部分计算损失）
    assistant_start_idx = full_text.find("<|start_header_id|>assistant<|end_header_id|>") + len("<|start_header_id|>assistant<|end_header_id|>\n")
    assistant_start_token = len(tokenizer(full_text[:assistant_start_idx], return_tensors="pt")["input_ids"][0])
    labels = [-100] * len(input_ids)
    labels[assistant_start_token:] = input_ids[assistant_start_token:]
    
    return {"input_ids": input_ids, "attention_mask": attention_mask, "labels": labels, "text": full_text}

# 加载原始数据并处理
raw_single_turn = [
  {
    "instruction": " 解释Kubernetes CRD在企业级存储系统（如PowerStore）中的作用？  ",
    "context": "PowerStore是戴尔的企业级统一存储系统，支持块、文件、对象存储。",
    "response": "Kubernetes CRD(自定义资源定义)可以将PowerStore的存储资源（如卷、快照）封装为K8s原生资源！管理员通过kubectl直接管理，不用调用存储API，简化集成~"
  }
]
dataset = Dataset.from_list(raw_single_turn)
processed_dataset = dataset.map(preprocess_single_turn, num_proc=4)
processed_dataset.save_to_disk("./llama3_storage_finetune_data")
```

------

### 四、核心说明

1. 格式是关键：特殊 token 是 LLaMA3 预训练时学习的标记，缺失会导致模型无法正确识别角色和对话边界；
2. 标签掩码：通过`-100`屏蔽非回复部分，确保微调仅优化模型的回答能力；
3. 长度控制：LLaMA3 默认 8192 tokens，按句子边界截断，避免语义断裂。

需要我把这个示例扩展为**完整可运行的微调脚本**（含 LoRA 配置、训练参数与损失计算），并适配你熟悉的**C++/Go 存储系统相关问答场景**吗？





# LoRA训练

【LoRA微调：带你手把手从零理解LoRA技术，让你的大模型微调不再烧钱！全程干货~大模型|LLM】 https://www.bilibili.com/video/BV1z1mMB6EF4/?share_source=copy_web&vd_source=57c839bee712e36d49139c5f4c8683ec



