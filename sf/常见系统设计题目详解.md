# 常见系统设计题目详解

# 1. 基础组件系统设计

基础组件是分布式系统的基石，聚焦于解决分布式环境下的共性问题，如唯一标识生成、资源竞争控制、服务间通信等，其设计质量直接决定上层业务系统的稳定性和性能。

## 1.1 设计一个分布式 ID 生成器

### 一、核心需求解析

- **全局唯一**：分布式环境下，不同节点、不同业务生成的 ID 不得重复，这是最基本的底线，避免数据冲突。

- **有序**：ID 需具备一定的顺序性，便于数据库索引优化（如 MySQL 主键自增索引效率最优）、日志排序、数据追溯等场景。

- **高可用**：生成器服务需 7×24 小时可用，单个或部分节点故障不影响整体服务，无单点风险。

- **低延迟**：ID 生成响应时间需极短（通常毫秒级以内），避免成为业务链路的性能瓶颈。

### 二、使用用例

- **电商订单ID生成**：某电商平台日均订单量超100万，分布在20个业务节点，需为每个订单生成唯一ID。ID需包含下单时间便于追溯，且支持按ID快速排序，采用雪花算法生成64位ID，确保订单数据无冲突，同时满足数据库索引优化需求。

- **物流单号生成**：物流公司全国有50个分拨中心，每个分拨中心每小时处理2万单包裹，需生成唯一物流单号。单号需体现分拨中心信息（节点ID）和揽收时间，采用定制化雪花算法，将节点ID字段扩展至12位，支持1024个分拨中心，满足业务扩张需求。

- **日志ID生成**：分布式系统包含100个服务节点，每个节点每秒钟产生100条日志，需为每条日志生成唯一标识。对有序性要求低，采用UUID优化方案（去除横线+前缀时间戳），既保证唯一性，又便于按时间范围筛选日志。

### 三、关键决策与方案选型

|方案类型|优点|缺点|适用场景|
|---|---|---|---|
|雪花算法（Snowflake）|1. 本地生成，低延迟；2. 有序性好，含时间戳；3. 可自定义比特分配，灵活扩展；4. 高可用，无中心化依赖|1. 依赖系统时钟，存在时钟回拨风险；2. 需提前规划节点 ID 分配，避免冲突|高并发、低延迟、有序性要求高的场景（如电商订单、物流单号）|
|数据库自增|1. 实现简单，依赖数据库原生能力；2. 绝对有序，索引友好；3. 无需额外开发服务|1. 数据库单点风险，需主从架构保障可用；2. 高并发下数据库易成为瓶颈；3. 分库分表时需处理 ID 冲突（如设置步长）|并发量较低、业务简单的小型系统|
|UUID 优化|1. 生成简单，无中心化依赖；2. 全球唯一，无需节点分配；3. 高可用，无单点故障|1. 无序，数据库索引性能差；2. 长度长（36位），存储和传输成本高；3. 无业务含义|对有序性无要求、低并发的场景（如日志ID、临时标识）|
**最终选型建议**：优先选择雪花算法，其在低延迟、有序性、高可用之间达到最佳平衡，可通过优化解决时钟回拨问题；若业务对有序性要求极低，可考虑 UUID 优化方案；数据库自增仅作为小型系统的过渡方案。

### 三、核心实现细节

#### 1. 雪花算法核心结构（64位Long型）

默认比特分配：符号位（1位，固定0）+ 时间戳（41位）+ 节点ID（10位）+ 序列号（12位）

- **符号位**：确保 ID 为正数，避免后续处理异常。

- **时间戳**：单位为毫秒，41位可表示约69年（2^41-1毫秒≈69年），需设置一个起始时间戳（如2020-01-01 00:00:00），计算相对时间差，延长可用周期。

- **节点ID**：10位可支持1024个节点，可按“机房ID（5位）+ 机器ID（5位）”分配，确保分布式环境下节点唯一。

- **序列号**：同一节点、同一毫秒内的ID计数器，12位可支持4096个ID/毫秒，满足高并发需求。

#### 2. 时钟回拨处理方案

时钟回拨是雪花算法的核心痛点，指系统时钟因同步或故障回退到过去的时间，可能导致ID重复，处理方案如下：

- **检测机制**：生成ID时，对比当前系统时间与上一次生成ID的时间戳，若当前时间戳小于上一次，则判定为时钟回拨。

- **轻微回拨（如5ms内）**：采用等待策略，休眠至当前时间戳大于上一次时间戳后再生成ID，适用于短暂的时钟波动。

- **严重回拨（如超过5ms）**：
        临时切换节点ID：提前预留部分“应急节点ID”，发生严重回拨时，自动切换至应急ID，确保ID不重复；

- 报警通知：立即触发运维报警，由人工介入排查时钟问题；

- 历史ID校验：生成ID后，可通过缓存或数据库短暂校验，避免重复（兜底策略）。

#### 3. 分布式部署一致性保障

- **节点ID分配**：通过配置中心（如Nacos、Zookeeper）统一分配节点ID，确保每个节点ID唯一，避免手动配置出错；节点启动时从配置中心获取ID，若获取失败则拒绝启动。

- **服务集群化**：部署多节点的ID生成服务，通过负载均衡（如Nginx、Gateway）分发请求，单个节点故障不影响整体服务；服务无状态，可水平扩展。

- **监控运维**：实时监控节点ID使用情况、ID生成QPS、时钟状态等指标，设置阈值报警（如某节点QPS突增、出现时钟回拨）。

## 1.2 设计一个分布式系统中的分布式锁

### 一、核心需求解析

- **互斥性**：在分布式环境下，同一时间只能有一个客户端持有同一把锁，确保临界资源的独占访问，避免并发修改冲突。

- **安全性**：锁只能被持有它的客户端释放，防止其他客户端恶意释放不属于自己的锁，导致锁机制失效。

- **高可用**：锁服务需具备高可用性，即使部分节点故障，仍能正常提供锁的获取和释放服务，无单点故障风险。

- **自动释放**：支持锁的自动过期释放，避免客户端因异常（如宕机、网络中断）无法主动释放锁，导致资源长期被占用形成死锁。

- **可重入性**：同一客户端在持有锁的情况下，再次请求获取同一把锁时应成功，满足复杂业务场景下的锁复用需求（如递归调用、多方法共享锁）。

### 二、使用用例

- **秒杀库存控制**：电商平台秒杀活动中，某商品库存1000件，同时有10万用户抢购，需确保同一时间只有一个用户能扣减同一件商品库存。采用Redis分布式锁，用户发起抢购时获取锁，扣减库存后释放锁，防止超卖，配合“看门狗”机制避免因网络延迟导致锁提前释放。

- **分布式任务调度**：系统中有10个任务节点，需调度执行“订单超时关闭”任务（每10分钟执行一次），确保同一订单仅被一个节点处理。基于ZooKeeper分布式锁，任务节点竞争锁，获取锁的节点执行任务，任务完成后释放锁，保障任务执行的唯一性。

- **数据同步互斥**：跨数据库数据同步服务部署在5个节点，需定期同步用户数据，同步过程中需锁定用户ID范围，避免多个节点重复同步同一批数据。采用数据库分布式锁，同步前通过唯一索引抢占锁，同步完成后释放，适用于并发量较低的场景。

### 三、关键决策与方案选型

|方案类型|核心实现|优点|缺点|适用场景|
|---|---|---|---|---|
|基于Redis的分布式锁|利用Redis的SETNX命令（不存在则设置）+ 过期时间实现，结合Lua脚本保证锁操作的原子性|1. 性能优异，支持高并发获取和释放锁；2. 部署和使用简单，客户端生态完善；3. 支持过期自动释放，避免死锁|1. 主从架构下存在锁丢失风险（主库宕机未同步锁信息）；2. 需解决锁过期时间与业务执行时间不匹配问题|高并发、对性能要求高的业务场景（如秒杀库存控制、分布式任务调度）|
|基于ZooKeeper的分布式锁|利用ZooKeeper的临时有序节点特性，通过节点创建、监听机制实现锁的竞争与释放|1. 天生支持高可用（集群部署）；2. 锁释放机制可靠（客户端断开自动删除临时节点）；3. 支持公平锁机制|1. 性能相对较差，不适合超高频锁操作；2. 部署和维护成本高，需关注集群稳定性|对可靠性要求极高、并发量适中的场景（如分布式事务协调、主从切换控制）|
|基于数据库的分布式锁|通过数据库唯一索引（如锁名称）或悲观锁（SELECT ... FOR UPDATE）实现|1. 实现逻辑简单，无需引入额外中间件；2. 依赖数据库事务特性，安全性有保障|1. 性能差，高并发下数据库易成为瓶颈；2. 易产生死锁，需额外设计超时释放机制；3. 存在单点风险（需数据库主从架构）|并发量低、业务简单的小型分布式系统，或作为临时过渡方案|
**最终选型建议**：优先选择基于Redis的分布式锁方案，其在性能和易用性上优势显著，可通过Redis Cluster或Redlock算法解决主从架构下的锁丢失问题；对可靠性要求极高的核心场景，可选用ZooKeeper方案；数据库方案仅作为低并发场景的备选。

### 三、核心实现细节

#### 1. 基于Redis的分布式锁实现（优化版）

- **核心命令设计（原子性保障）**：

- 锁获取：使用带NX（不存在才设置）、PX（过期时间毫秒）参数的SET命令，并设置唯一值（如客户端ID+UUID）作为锁标识，确保锁只能被持有者释放。命令示例：`SET lock:order:1001 clientA:uuid123 NX PX 30000`，该命令为原子操作，避免“检查-设置”的竞态条件。

- 锁释放：通过Lua脚本实现“判断锁标识+删除锁”的原子操作，脚本逻辑为：若当前锁的值等于客户端标识，则删除锁，否则返回失败。避免客户端释放其他客户端持有的锁。

- 锁续期：针对业务执行时间可能超过锁过期时间的场景，引入“看门狗”机制，客户端持有锁后启动后台线程，每隔1/3锁过期时间（如10秒）检查锁是否仍被持有，若持有则自动延长锁的过期时间，确保业务执行期间锁不被释放。

#### 2. 高可用优化（解决Redis主从锁丢失问题）

- **Redis Cluster部署**：将Redis部署为集群模式（至少3主3从），锁的Key通过哈希分布在不同主节点上，单个主节点故障时，其从节点会自动切换为主节点，确保锁服务的连续性。

- **Redlock算法引入**：在极端高可靠需求场景，采用Redlock算法，客户端向多个独立的Redis集群（通常3-5个）发起锁获取请求，只有当超过半数集群获取锁成功时，才认为锁获取成功，通过多集群冗余避免单集群故障导致的锁丢失。

#### 3. 异常场景处理

- **客户端宕机处理**：依赖Redis的过期自动释放机制，锁会在预设的过期时间后自动删除，其他客户端可重新竞争锁，避免死锁。

- **网络波动处理**：客户端与Redis之间出现短暂网络波动时，“看门狗”线程可能无法正常续期，导致锁被释放。此时需在业务逻辑中增加幂等性处理，确保即使其他客户端获取锁执行相同业务，也不会产生数据不一致。

- **锁竞争激烈处理**：当大量客户端竞争同一把锁时，采用“自旋+随机延迟”策略，客户端获取锁失败后不立即返回，而是短暂自旋等待（如50ms）后再次尝试，随机延迟可避免多个客户端同时重试导致的“惊群效应”。

#### 4. 可重入性实现

- 通过Redis的Hash数据结构实现，Key为锁名称，Field为客户端标识，Value为锁的重入次数。

- 锁获取逻辑：若锁不存在，则创建Hash并设置重入次数为1；若锁已存在且客户端标识匹配，则重入次数加1；若客户端标识不匹配，则获取失败。

- 锁释放逻辑：客户端释放锁时，将重入次数减1，当重入次数减为0时，删除整个Hash键，完成锁的释放。

## 1.3 设计一个简单的消息队列（MQ）

### 一、核心需求解析

- **异步通信**：解除服务间的同步调用依赖，如用户下单后，异步触发库存扣减、物流创建等操作，提升主流程响应速度。

- **解耦服务**：服务间通过MQ传递消息，无需感知对方的部署地址、接口细节，降低系统耦合度，便于独立开发和迭代。

- **削峰填谷**：应对突发高流量（如秒杀、促销），将瞬时大量请求缓存到MQ中，由消费端按能力匀速处理，避免下游服务被压垮。

- **消息可靠性**：确保消息“不丢、不重、不重复消费”，这是MQ的核心质量指标，避免业务数据不一致（如订单创建成功但库存未扣减）。

### 二、使用用例

- **电商下单异步处理**：用户在电商平台下单后，需触发库存扣减、订单创建、物流预约、积分发放等操作。通过MQ实现异步通信，下单服务发送消息后立即返回“下单成功”，库存、物流等服务异步消费消息，提升主流程响应速度，避免某环节故障导致下单失败。

- **秒杀流量削峰**：秒杀活动瞬时请求量达10万QPS，而下游订单处理服务仅能支撑2万QPS。将秒杀请求发送至MQ，订单服务按能力匀速消费，避免下游服务被压垮，同时通过消息持久化确保请求不丢失。

- **跨系统通知推送**：用户完成支付后，需向电商系统、会员系统、财务系统推送支付结果。采用发布订阅模式，支付服务将消息发布至“支付成功”主题，各系统订阅该主题获取消息，实现服务解耦，新增通知系统时无需修改支付服务代码。

### 三、关键决策与方案选型

#### 1. 存储设计：磁盘 vs 内存

|存储类型|优点|缺点|适用场景|
|---|---|---|---|
|磁盘存储（如RocketMQ、Kafka）|1. 消息持久化，节点故障后消息不丢失；2. 支持海量消息存储，不受内存容量限制；3. 可通过磁盘分区、索引优化提升性能|1. 读写延迟高于内存；2. 需设计高效的磁盘IO策略（如顺序写）|对消息可靠性要求高、需存储大量历史消息的场景（如电商订单、金融交易）|
|内存存储（如Redis、RabbitMQ内存模式）|1. 读写速度极快，延迟低（微秒级）；2. 实现简单，无需复杂的磁盘优化逻辑|1. 消息易丢失（节点重启、宕机）；2. 存储容量有限，无法支撑海量消息；3. 需配合持久化机制（如RDB/AOF）弥补可靠性缺陷|对延迟要求极高、消息可容忍短暂丢失的场景（如实时监控、临时通知）|
**选型建议**：优先选择磁盘存储+持久化策略，兼顾可靠性和存储能力；若业务对延迟要求极致且可接受消息丢失风险，可采用内存存储+定期快照备份。

#### 2. 生产消费模型：点对点 vs 发布订阅

- **点对点模型（P2P）**：
        核心逻辑：消息队列中的消息只能被一个消费者消费，消费后消息从队列中删除。

- 实现方式：基于队列（Queue）实现，消费者主动拉取或被动推送消息。

- 适用场景：任务分发（如订单处理、日志分析），确保每个任务仅被执行一次。

**发布订阅模型（Pub/Sub）**：
        核心逻辑：生产者将消息发布到主题（Topic），多个订阅该主题的消费者均可收到消息，实现“一对多”通信。

实现方式：基于主题+订阅者机制，消息发布后复制到每个订阅者的消费队列中。

适用场景：通知推送（如订单状态变更、活动公告）、数据广播（如实时日志同步）。

**选型建议**：设计时支持两种模型的灵活切换，通过配置队列类型（Queue/Topic）实现；底层可统一采用“主题+队列”架构，P2P模型本质是“单订阅者的Topic”。

### 三、核心实现细节

#### 1. 消息存储核心设计（磁盘存储为例）

- **文件结构**：采用“主题-队列-文件组”三级结构，每个主题下包含多个队列（提升并发度），每个队列对应一组日志文件（CommitLog）和索引文件（ConsumeQueue）。

- **顺序写优化**：消息写入时采用磁盘顺序写（而非随机写），利用磁盘缓存提升IO效率；单个CommitLog文件大小固定（如1GB），满后自动滚动生成新文件，便于日志清理和归档。

- **索引设计**：ConsumeQueue作为消息的索引文件，存储“CommitLog偏移量、消息长度、消费标记”等信息，消费者通过ConsumeQueue快速定位到CommitLog中的消息，避免全量扫描。

- **持久化策略**：支持同步刷盘和异步刷盘配置，同步刷盘（消息写入后立即刷盘）确保消息不丢失，适合核心业务；异步刷盘（批量刷盘）提升性能，适合非核心业务。

#### 2. 消息确认机制（ACK）与可靠性保障

- **ACK机制流程**：
        消费者拉取消息后，MQ将消息标记为“待消费”状态，设置超时时间（如30秒）；

- 消费者处理完成后，向MQ发送ACK确认消息（可分为“成功ACK”和“失败ACK”）；

- MQ收到成功ACK后，将消息标记为“已消费”并从消费队列中删除；收到失败ACK或超时未ACK时，将消息重新放入队列尾部，等待重试。

- **不丢消息保障**：
        生产者端：采用“同步发送+确认机制”，消息发送后等待MQ的写入确认（确保消息已持久化），失败则重试；

- MQ端：消息写入磁盘并刷盘后才返回确认，节点故障时通过多副本复制（如主从架构）确保消息不丢失；

- 消费者端：采用“先处理业务，后发送ACK”的顺序，避免业务处理失败但已ACK导致消息丢失。

**不重消息保障**：
        消息唯一标识：为每个消息生成全局唯一ID（如雪花算法ID），消费者端基于消息ID做幂等处理（如存入Redis，消费前判断是否已处理）；

消费进度管理：MQ记录每个消费者的消费进度（如消费到的消息偏移量），重启后基于进度继续消费，避免重复拉取。

#### 3. 重试策略与死信队列

- **重试策略**：
        重试次数控制：设置最大重试次数（如3次），超过次数则不再重试，避免无效循环；

- 重试延迟策略：采用“指数退避”策略，重试间隔逐渐增加（如1s、3s、5s），减轻下游服务压力；

- 重试触发条件：消费者发送失败ACK、消费超时、服务宕机等场景自动触发重试。

**死信队列（DLQ）**：
        核心作用：存储超过最大重试次数仍处理失败的消息，避免消息丢失且不影响正常消息消费；

实现方式：为每个普通队列绑定一个对应的死信队列，消息达到重试上限后自动转发至死信队列；

后续处理：提供死信消息查询界面，支持人工介入处理（如修复业务问题后重新发送），或定时归档分析失败原因。

# 2. 互联网核心业务系统设计

## 2.1 设计一个社交媒体的 Feed 流系统（如朋友圈、微博）

### 一、核心需求解析

- **发布动态**：用户快速发布文本、图片、视频等内容，支持@好友、添加话题等功能，发布后即时生效。

- **好友动态展示**：用户可查看好友或关注对象的动态列表，按时间倒序排列，支持点赞、评论、转发等互动操作。

- **实时性**：好友发布新动态后，用户能在短时间内（如1-3秒）看到，尤其是核心社交关系（如亲密好友）的动态。

- **高并发**：支持百万用户同时刷新Feed流，峰值QPS可达10万+，需避免系统卡顿或崩溃。

### 二、使用用例

- **朋友圈动态展示**：用户A发布朋友圈后，其50个好友需在刷新时看到该动态。采用混合模式，普通好友通过推模式将动态写入其个人时间线，明星好友（如粉丝超10万）通过拉模式获取动态，确保A发布后普通好友实时看到，同时避免明星好友的时间线被大量推送压垮。

- **微博热点扩散**：某明星发布微博后，其1000万粉丝需获取该动态。采用拉模式，粉丝刷新时主动拉取明星的发布时间线，配合CDN缓存热点动态内容，支撑高并发访问，同时避免发布时的推送风暴。

- **好友互动实时提醒**：用户B点赞用户A的动态后，A需实时收到提醒。通过推模式，将“点赞提醒”推送到A的通知时间线，A刷新时立即展示，提升社交互动体验。

### 三、关键决策与方案选型

#### 1. 数据模型：推模式 vs 拉模式 vs 混合模式

|模式类型|核心逻辑|优点|缺点|适用场景|
|---|---|---|---|---|
|推模式（Push）|用户发布动态后，将动态主动推送到所有关注者的“个人时间线”（Timeline）中|1. 读取效率高，用户刷新时直接读取个人Timeline；2. 实时性好，动态即时推送|1. 明星用户发布动态时，推送压力极大（如千万粉丝）；2. 存储冗余，同一动态多份存储|普通用户、关注关系少的场景|
|拉模式（Pull）|用户发布动态后，仅存储在自己的“发布时间线”中；用户刷新时，主动拉取所有关注者的发布时间线并合并排序|1. 发布压力小，无需推送；2. 无存储冗余，动态仅存一份|1. 读取效率低，合并排序耗时；2. 实时性差，用户不刷新则无法获取新动态|明星用户、关注关系极多的场景|
|混合模式|结合推、拉模式，普通用户采用推模式，明星用户采用拉模式；或核心好友推模式，非核心好友拉模式|1. 平衡发布与读取压力；2. 兼顾实时性与系统性能；3. 灵活适配不同用户场景|1. 实现复杂，需区分用户类型和关系；2. 需动态调整策略|混合用户结构的社交媒体（如微博、朋友圈）|
**最终选型**：采用混合模式，是当前主流社交媒体的最优解。

### 三、核心实现细节

#### 1. 混合模式下的 Timeline 设计

- **双时间线存储**：
        发布时间线（Publish Timeline）：每个用户对应一个，存储该用户发布的所有动态ID，按发布时间倒序排列，基于Redis Sorted Set实现（score为时间戳）；

- 个人时间线（Home Timeline）：每个用户对应一个，存储关注者推送的动态ID（仅普通用户推送），按发布时间倒序排列，同样基于Redis Sorted Set实现。

**动态发布流程**：
        用户发布动态，生成动态ID（雪花算法），存储动态内容到MySQL/HBase（文本、图片URL等）；

将动态ID写入该用户的Publish Timeline；

查询该用户的关注者列表，区分普通用户和明星用户：
            普通关注者：将动态ID推送到其Home Timeline；

明星关注者：不推送，仅在其刷新时拉取。

**Feed流刷新流程**：
        用户刷新Feed流时，先读取自己的Home Timeline，获取普通关注者的动态ID；

同时拉取明星关注者的Publish Timeline，获取其最新动态ID；

将两部分动态ID合并，按时间戳排序（去重），取Top N条；

根据动态ID查询MySQL/HBase获取完整动态内容，返回给用户。

#### 2. 缓存分层与性能优化

- **多级缓存架构**：
        L1缓存：应用本地缓存（如Caffeine），缓存热点用户的Home Timeline和高频访问的动态内容，延迟最低（微秒级）；

- L2缓存：分布式缓存（如Redis集群），存储所有用户的Timeline和动态ID映射，支持水平扩展；

- L3存储：MySQL/HBase，存储完整动态内容和用户关系数据，作为缓存的兜底。

- **分页策略：游标分页**：
        传统的offset-limit分页在数据量大时性能差（如offset=10000时需扫描前10000条数据），采用游标分页优化：以最后一条动态的时间戳作为游标（cursor），用户下拉刷新时，传入游标和页大小；

- Redis Sorted Set通过ZREVRANGEBYSCORE命令，快速查询小于游标时间戳的Top N条数据，性能稳定（O(logN)）；

- 支持“上拉加载更多”和“下拉刷新最新”两种场景，游标分页天然适配。

**热点处理：明星用户动态分流**：
        单独部署明星用户服务集群，处理其动态发布和拉取请求，与普通用户服务隔离；

明星用户的Publish Timeline采用Redis主从架构，主库写入，多从库读取，分散拉取压力；

动态内容预热：明星用户发布动态后，提前将内容缓存到CDN和应用本地缓存，应对突发访问高峰。

## 2.2 设计一个电商订单系统

### 一、核心需求解析

- **创建订单**：用户下单时，快速完成商品校验、库存检查、价格计算、订单生成等流程，响应时间控制在数百毫秒内。

- **库存扣减**：确保库存准确，避免超卖（核心痛点），支持秒杀等高频扣减场景，同时防止库存锁定过长导致资源浪费。

- **支付回调**：支持多支付渠道（微信、支付宝等），准确接收支付结果回调，及时更新订单状态，处理回调延迟或重复问题。

- **订单查询**：用户和商家可快速查询订单详情、状态、物流等信息，支持按订单号、时间、状态等多维度查询。

- **高可用（秒杀场景）**：秒杀时订单QPS突增（如10万QPS），系统需稳定运行，无宕机、无超卖，支持流量快速恢复。

### 二、使用用例

- **普通商品下单**：用户购买一件衣服，需完成商品校验、库存扣减、订单生成、支付创建。采用TCC方案，Try阶段锁定库存和创建预订单，Confirm阶段确认扣减库存和生成正式订单，Cancel阶段在支付超时后释放库存，确保各环节数据一致。

- **秒杀订单处理**：用户参与秒杀活动抢购手机，库存仅50台，瞬时请求达5万。通过Redis预扣减库存拦截无效请求，Kafka缓冲订单请求，订单服务异步创建订单，配合分库分表存储订单数据，支撑高并发且无超卖。

- **支付回调处理**：用户使用支付宝支付后，支付宝向电商系统推送支付结果。回调服务验证签名后，更新订单状态，触发物流创建和积分发放，通过分布式锁和唯一键确保回调请求仅被处理一次，避免重复更新。

### 三、关键决策与方案选型

#### 1. 分布式事务方案

|方案类型|核心逻辑|优点|缺点|适用场景|
|---|---|---|---|---|
|2PC（两阶段提交）|协调者分“准备阶段”和“提交阶段”，所有参与者准备完成后才统一提交，否则回滚|强一致性，实现逻辑清晰|1. 同步阻塞，性能差；2. 协调者单点故障风险；3. 部分提交导致数据不一致|金融核心交易，对一致性要求极高的场景|
|TCC（补偿事务）|分Try（资源预留）、Confirm（确认执行）、Cancel（补偿回滚）三阶段，业务代码侵入式开发|1. 性能好，异步非阻塞；2. 一致性可控；3. 支持复杂业务场景|1. 开发成本高，需手写补偿逻辑；2. 补偿逻辑需保证幂等|电商订单、库存扣减等核心业务，兼顾性能和一致性|
|最终一致性（消息队列）|基于消息可靠投递，通过“本地事务+消息表”或“事务消息”实现，异步完成数据同步，允许短暂不一致|1. 性能极佳，无阻塞；2. 开发成本低；3. 高可用，易扩展|1. 一致性延迟，需设计幂等和重试机制；2. 不适合强一致性场景|订单状态同步、物流创建、积分发放等非核心一致性场景|
**选型建议**：采用“TCC+最终一致性”混合方案，订单创建+库存扣减核心流程用TCC保证强一致性，订单状态同步、积分发放等附属流程用最终一致性方案提升性能。

#### 2. 库存锁设计：悲观锁 vs 乐观锁

- **悲观锁**：
        核心逻辑：认为库存扣减冲突概率高，在操作前锁定库存记录（如MySQL的SELECT ... FOR UPDATE），操作完成后释放锁。

- 优点：实现简单，避免并发冲突，无超卖风险。

- 缺点：并发性能差，大量请求阻塞等待锁，易导致死锁；秒杀场景下完全不可用。

- 适用场景：低并发库存操作（如普通商品下单）、库存调整等后台操作。

**乐观锁**：
        核心逻辑：认为库存扣减冲突概率低，不提前锁记录，通过版本号或库存对比实现并发控制（如UPDATE stock SET num=num-1 WHERE id=? AND num>0 AND version=?）。

优点：并发性能好，无锁竞争，支持高QPS场景。

缺点：需处理更新失败的重试逻辑；极端高并发下重试次数多，可能导致用户体验差。

适用场景：高并发库存操作（如秒杀、促销），普通商品下单的优化方案。

**选型建议**：秒杀场景采用“Redis预扣减+MySQL最终确认”的乐观锁方案；普通场景采用MySQL版本号乐观锁，减少锁竞争。

### 三、核心实现细节

#### 1. 订单创建核心流程（TCC方案）

1. **Try阶段（资源预留）**：
        订单服务：生成预订单（状态为“待支付”），写入订单库，记录订单信息（商品ID、数量、价格等）；

2. 库存服务：预扣减库存，将库存状态标记为“已锁定”，记录锁定记录（订单ID、商品ID、锁定数量），确保库存充足（num > 锁定数量）；

3. 支付服务：创建支付单，关联订单ID，返回支付链接或二维码。

4. **Confirm阶段（确认执行）**：
        用户支付成功后，支付服务触发回调，通知订单服务；

5. 订单服务：将预订单状态更新为“已支付”，触发Confirm操作；

6. 库存服务：将“已锁定”库存转为“已扣减”，删除锁定记录；

7. 通知物流、积分等服务，异步处理后续流程（最终一致性方案）。

8. **Cancel阶段（补偿回滚）**：
        触发条件：用户支付超时（如30分钟）、支付失败、主动取消订单；

9. 订单服务：将订单状态更新为“已取消”；

10. 库存服务：释放锁定库存，将库存数量加回，删除锁定记录；

11. 支付服务：关闭支付单，禁止后续支付。

#### 2. 秒杀场景库存与订单优化

- **库存预热与Redis预扣减**：
        秒杀活动开始前，将商品库存数量同步到Redis中（如SET stock:1001 1000），作为库存预扣减的依据；

- 用户秒杀时，先通过Redis的DECR命令预扣减库存，若返回值>=0，说明预扣减成功，允许创建订单；若返回值<0，直接返回“秒杀失败”，拦截无效请求；

- 预扣减成功后，异步同步到MySQL库存表，确保最终一致性（通过定时任务校验Redis与MySQL库存差异）。

- **订单分库分表**：
        分片策略：按“用户ID哈希+订单创建时间”复合分片，用户ID哈希确保同一用户的订单落在同一分库，便于查询；时间分片（如按月份）控制单表数据量（不超过1000万条）；

- 中间件选型：采用Sharding-JDBC实现分库分表逻辑，透明化分片操作，上层业务无需感知；

- 订单查询优化：建立订单号索引（雪花算法订单号含时间戳），支持按订单号快速定位分库分表；用户订单查询按用户ID路由到对应分库，效率极高。

**降级策略**：
        流量入口降级：秒杀时关闭订单详情页的非核心功能（如评价、推荐商品），简化页面渲染，提升响应速度；

服务降级：非核心服务（如积分、优惠券）采用降级策略，秒杀期间仅记录日志，后续异步补偿；

熔断保护：当订单服务QPS超过阈值或错误率升高时，触发熔断，返回“系统繁忙，请稍后重试”，避免服务雪崩。

#### 3. 支付回调处理与幂等性保障

- **回调流程设计**：
        支付渠道（微信/支付宝）通过预设的回调地址推送支付结果，携带订单号、支付金额、签名等信息；

- 回调服务验证签名（确保请求来自合法渠道），解析参数，查询本地支付单校验金额一致性；

- 若订单状态已为“已支付”，直接返回成功（幂等处理）；若未支付，更新订单和支付单状态，触发后续流程；

- 返回支付渠道指定格式的成功响应（如微信要求返回<xml><return_code>SUCCESS</return_code></xml>），否则支付渠道会重复推送。

- **幂等性保障**：
        基于订单号唯一键：更新订单状态时，使用UPDATE ... WHERE 订单号=? AND 状态=?（如状态为“待支付”），确保同一订单仅被更新一次；

- 分布式锁：使用Redis分布式锁（如SETNX order:lock:1001 1 EX 10），确保同一订单的回调请求仅被处理一次；

- 日志记录：记录所有回调请求的详细信息（参数、时间、处理结果），便于问题排查和重复请求分析。

## 2.3 设计一个短视频推荐系统（简化版）

### 一、核心需求解析

- **用户行为采集**：全面收集用户与短视频的交互行为（观看、点赞、评论、转发、收藏、停留时长等），为个性化推荐提供数据支撑。

- **个性化推荐**：基于用户行为和视频内容，为不同用户推荐其感兴趣的视频，提升用户停留时长和互动率。

- **视频加载低延迟**：用户滑动切换视频时，加载时间控制在数百毫秒内，避免卡顿，提升观看体验。

### 二、使用用例

- **新用户冷启动推荐**：新用户注册时选择“音乐”“美食”兴趣标签，系统立即为其推荐相关热门短视频。采用内容推荐策略，基于标签匹配视频内容特征，生成初始推荐列表，解决新用户无行为数据的问题。

- **成熟用户个性化推荐**：用户C使用APP1个月，喜欢点赞“宠物”“搞笑”类视频，系统需为其推荐相似内容。采用混合策略，通过协同过滤找到喜欢同类视频的相似用户，结合内容推荐匹配宠物搞笑类视频，提升推荐准确率。

- **视频加载优化**：用户滑动短视频时，需在300ms内完成视频加载。通过CDN加速视频传输，预加载下一个推荐视频的前3秒内容，结合视频转码适配不同网络环境，确保加载流畅。

### 三、关键决策与方案选型

#### 1. 推荐策略：协同过滤 vs 内容推荐

|策略类型|核心逻辑|优点|缺点|适用场景|
|---|---|---|---|---|
|协同过滤|基于“人以群分、物以类聚”，分为用户协同（相似用户喜欢的视频）和物品协同（相似视频）|1. 无需视频内容分析，适用范围广；2. 推荐结果惊喜度高，可发现潜在兴趣|1. 冷启动问题（新用户/新视频无数据）；2. 稀疏性问题（用户行为少导致推荐不准）|有一定用户行为数据的成熟用户|
|内容推荐|基于视频内容特征（标题、标签、画面、音频）和用户兴趣标签，匹配相似内容|1. 冷启动友好（新视频可基于内容标签推荐）；2. 推荐解释性强，用户易理解|1. 依赖内容特征提取精度，需AI算法支持；2. 推荐范围窄，易陷入“信息茧房”|新用户、新视频，或用户兴趣明确的场景|
**选型建议**：采用“协同过滤+内容推荐”的混合策略，新用户/新视频优先使用内容推荐，有行为数据后结合协同过滤，提升推荐准确性和多样性。

#### 2. 存储分层设计

- **用户行为数据**：选用HBase，原因如下：
        海量数据存储：支持PB级数据存储，满足用户行为日志的持续增长；

- 列存储优势：用户行为数据为多维度稀疏数据，列存储可提升查询和存储效率；

- 按时间范围查询：支持按用户ID+时间戳作为RowKey，快速查询用户历史行为。

**推荐结果数据**：选用Redis集群，原因如下：
        低延迟访问：推荐结果需快速返回给用户，Redis的内存存储满足毫秒级响应；

数据结构适配：采用List存储用户的推荐视频列表，支持快速获取和更新；

水平扩展：Redis集群支持分片，可应对高并发查询。

**视频元数据**：选用MySQL，存储视频ID、标题、标签、作者、时长等结构化数据，支持复杂条件查询。

**视频文件**：选用对象存储（如OSS、S3），配合CDN加速，降低视频加载延迟。

### 三、核心实现细节

#### 1. 数据采集与处理流程

1. **行为采集层**：
        客户端埋点：在APP中嵌入埋点SDK，采集用户行为（如播放开始、暂停、点赞时触发埋点），包含用户ID、视频ID、行为类型、时间戳、设备信息等字段；

2. 服务端埋点：采集视频播放完成率、加载成功率等服务端数据，补充客户端埋点的不足；

3. 数据传输：采用HTTP/HTTPS协议将埋点数据实时发送到采集服务，或通过本地缓存批量发送（减少网络请求）。

4. **数据缓冲层**：
        采用Kafka作为消息队列，接收埋点数据，实现“生产-消费”解耦；

5. 按行为类型（如观看、点赞）分区，提升消费并发度，应对高流量（如百万用户同时观看）。

6. **数据处理层**：
        实时处理：采用Flink/Spark Streaming消费Kafka数据，实时计算用户实时兴趣（如最近1小时喜欢的视频类型），更新Redis中的临时兴趣标签；

7. 离线处理：采用Spark离线计算，每天/每小时计算用户长期兴趣模型、视频相似度矩阵、用户相似度矩阵，存储到HBase和MySQL中。

#### 2. 个性化推荐核心流程

1. **推荐候选集生成**：
        新用户：基于用户注册时填写的兴趣标签（如音乐、游戏、美食），从MySQL中查询对应标签的热门视频，生成初始候选集；

2. 成熟用户：
            内容推荐：提取用户喜欢的视频标签（如从点赞视频中统计Top5标签），匹配相同标签的视频；

3. 协同过滤：查询相似用户喜欢的视频（用户协同）和相似视频（物品协同），加入候选集；

4. 候选集去重：移除用户已观看过的视频，确保推荐新鲜度。

5. **推荐排序与过滤**：
        排序算法：采用LRU（逻辑回归）或深度学习模型（如DeepFM），将候选集按用户点击概率排序，排序特征包括用户兴趣匹配度、视频热度、时效性等；

6. 过滤规则：过滤低质量视频（如举报率高、播放完成率低）、违规视频，确保推荐内容合规。

7. **推荐结果缓存与更新**：
        将排序后的Top N视频ID（如100条）存入Redis，键为“user:recommend:1001”，值为视频ID列表，设置过期时间（如2小时）；

8. 用户滑动视频时，从Redis中批量获取视频ID（如每次获取10条），同时异步触发推荐结果更新，确保下次刷新时有新内容；

9. 实时更新：用户产生新行为（如点赞）时，实时调整推荐列表，将相似视频提前。

#### 3. 视频加载低延迟优化（CDN加速）

- **视频预处理**：
        转码适配：将视频转码为多种分辨率（如480P、720P、1080P）和格式（MP4、HLS），客户端根据网络状况和设备性能自动选择；

- 切片处理：采用HLS/DASH协议将视频切分为小切片（如10秒/片），支持边播边下载，减少初始加载时间。

**CDN加速策略**：
        节点调度：CDN根据用户IP地址和网络质量，调度至最近的边缘节点（如用户在北京，调度至北京CDN节点），缩短网络传输距离；

缓存策略：热门视频（播放量高）缓存到CDN边缘节点，用户请求直接从边缘节点获取，无需回源到对象存储；

预加载：基于推荐结果，在用户观看当前视频时，预加载下一个推荐视频的前几个切片，实现“无缝切换”。

# 3. 存储 / 数据密集型系统设计

聚焦 “海量数据处理”，考察存储与计算的协同设计，核心解决“数据存得下、查得快、不丢失”的问题，同时兼顾系统的可扩展性和容错能力。

## 3.1 设计一个支持海量日志存储与查询的系统（如 ELK 简化版）

### 一、核心需求解析

- **日志采集**：支持多来源、多格式日志的实时采集，包括应用服务器日志（如Tomcat、Nginx）、业务系统日志（如订单操作日志）、设备日志等，采集过程不影响业务系统性能。

- **海量存储**：每日日志数据量可达TB级，需支持长期存储（如30天、90天），存储成本可控，同时保证数据完整性。

- **实时查询**：支持按关键词、时间范围、日志类型、服务名称等多维度组合查询，查询响应时间控制在秒级（复杂查询不超过10秒），满足问题排查和业务分析需求。

- **按时间范围检索**：日志天然带有时间属性，需优化时间维度查询性能，支持“近1小时”“近24小时”“自定义时间区间”等高频查询场景。

### 二、使用用例

- **应用故障排查**：电商系统某订单服务出现500错误，运维人员需快速定位问题。通过ELK系统，按“服务名称=订单服务”“时间范围=近10分钟”“日志级别=ERROR”查询，秒级获取错误日志和堆栈信息，定位到数据库连接池耗尽问题。

- **业务数据统计**：运营人员需统计“双11”期间各地区的订单量分布。通过ES聚合功能，按“地区”字段分组统计日志中的订单数，生成可视化报表，支撑业务决策。

- **安全审计**：财务系统需留存3个月的操作日志，用于合规审计。系统按天创建日志索引，自动归档超过7天的冷数据至低成本存储，满足长期存储需求，同时保证近期日志的查询性能。

### 三、关键决策与方案选型

#### 1. 日志采集工具选型

|工具类型|核心优势|适用场景|部署成本|
|---|---|---|---|
|FileBeat|1. 轻量级，资源占用低（CPU/内存消耗极小）；2. 内置断点续传，避免日志丢失；3. 支持文件监控和日志轮转适配|应用服务器、数据库服务器等单机日志采集|低，无需复杂配置，可批量部署|
|Fluentd|1. 插件丰富，支持多格式日志解析（JSON、CSV等）；2. 支持分布式部署，可作为日志转发节点；3. 数据过滤能力强|复杂日志格式、多源日志聚合转发场景|中，需根据日志格式配置插件|
|Logstash|1. 数据处理能力强，支持正则提取、字段转换等复杂操作；2. 与Elasticsearch生态无缝集成|日志集中处理、清洗场景（作为采集链路的中间节点）|高，资源占用大，不适合单机直接采集|
**选型建议**：采用“FileBeat+Logstash”的二级采集架构，FileBeat部署在各业务节点负责前端采集，Logstash部署在中心节点负责数据清洗和转发，兼顾轻量性和处理能力。

#### 2. 存储与索引选型

核心选型：Elasticsearch（ES），而非传统关系型数据库或文件系统，原因如下：

- **分词索引能力**：支持对日志文本进行分词处理（如中文分词、英文分词），可基于任意关键词快速检索，远超传统数据库的模糊查询性能；

- **分布式架构**：天然支持分片和副本机制，可通过增加节点水平扩展存储和查询能力，应对TB级数据；

- **时间序列优化**：支持按时间字段创建索引（如按天创建索引 log-2025-12-04），极大提升时间范围查询效率，同时便于日志按时间归档和删除；

- **聚合分析能力**：支持统计日志条数、按字段分组统计（如按错误类型统计数量）等聚合操作，满足业务分析需求。

### 三、核心实现细节

#### 1. 系统整体架构（简化ELK）

采用“采集-传输-存储-查询”四层架构，对应组件：FileBeat（采集）→ Kafka（传输缓冲）→ Logstash（处理）→ Elasticsearch（存储索引）→ Kibana（查询可视化）

1. **采集层（FileBeat）**：

2. 部署在每台业务服务器上，配置监控日志目录（如/var/log/app/）和文件匹配规则（如*.log）；

3. 采用“行尾监听”机制，实时采集新增日志，通过“harvester”进程管理单个日志文件，支持日志文件轮转（如按大小、按时间轮转）时自动切换；

4. 将采集到的日志批量发送至Kafka，配置重试机制（如重试3次）和超时时间（如10秒），避免网络波动导致日志丢失。

5. **传输缓冲层（Kafka）**：

6. 创建按日志类型分区的Topic（如log-app、log-nginx、log-db），实现日志分类传输；

7. 每个Topic配置多副本（如3副本），确保日志数据在传输过程中不丢失；

8. 作为采集层与处理层的缓冲，应对日志突发峰值（如系统故障时错误日志激增），避免Logstash被压垮。

9. **处理层（Logstash）**：

10. 从Kafka消费日志数据，执行数据清洗操作：解析日志格式（如将JSON格式日志提取为结构化字段）、过滤无效日志（如过滤DEBUG级别日志）、添加额外字段（如服务器IP、服务名称）；

11. 通过grok插件解析非结构化日志（如Nginx的access.log），将“192.168.1.1 - [04/Dec/2025:10:00:00 +0800] "GET /api HTTP/1.1" 200 1024”解析为“客户端IP、时间、请求方法、URL、状态码、响应大小”等结构化字段；

12. 将处理后的结构化日志批量写入Elasticsearch，配置索引命名规则（如log-app-%{+YYYY.MM.dd}）。

13. **存储与查询层（Elasticsearch+Kibana）**：

14. Elasticsearch按日志类型和时间创建索引，配置分片策略（如每个索引3个主分片、2个副本分片），主分片分布在不同节点提升并发查询能力；

15. 针对日志字段设置不同的索引类型：时间字段（@timestamp）设为date类型，关键词字段（如服务名、错误码）设为keyword类型（支持精确匹配），文本字段（如日志内容）设为text类型（支持分词查询）；

16. Kibana提供可视化查询界面，支持通过DSL语句编写复杂查询条件，生成日志趋势图、错误统计报表等，辅助运维和业务分析。

#### 2. 分片与压缩策略优化

- **分片策略**：采用“按时间+日志类型”复合分片，具体为：

- 按时间分片：每日创建独立索引（如log-app-2025-12-04），超过保留期（如90天）的索引自动删除或归档至低成本存储（如S3）；

- 按日志类型分片：不同类型的日志写入不同索引（如应用日志、Nginx日志分开存储），避免单索引数据量过大，提升查询时的索引扫描效率；

- 分片大小控制：单个主分片大小控制在20-30GB，确保分片加载速度和查询性能，当索引数据量达到阈值时自动滚动生成新索引（通过ILM策略实现）。

- **压缩策略**：

- 索引压缩：Elasticsearch默认支持LZ4压缩算法，对日志文本的压缩率可达50%-70%，显著降低存储成本；

- 字段过滤：仅对需要查询的字段建立索引，对超大文本字段（如堆栈信息）设置“index: false”，仅存储不索引，减少索引开销；

- 冷热数据分离：将最近7天的热数据存储在高性能节点（使用SSD硬盘），7天以上的冷数据迁移至低成本节点（使用机械硬盘），平衡性能和成本。

## 3.2 设计一个分布式文件系统（简化版 HDFS）

### 一、核心需求解析

- **大文件存储**：支持GB/TB级大文件存储（如视频文件、数据分析原始文件），避免传统文件系统对大文件的处理瓶颈。

- **高可靠**：通过数据多副本存储确保文件不丢失，单个节点故障后数据可快速恢复，系统可用性达到99.99%。

- **高吞吐**：支持对大文件的高并发读写，尤其是顺序读写场景（如数据分析时的批量读取），吞吐量可达GB/s级。

- **可扩展**：支持通过增加节点横向扩展存储容量和处理能力，扩展过程对上层业务透明。

### 二、使用用例

- **短视频平台文件存储**：平台每日上传10万条短视频（平均每条500MB），需安全存储且支持高并发读取。通过分布式文件系统，将视频拆分为128MB数据块，3副本存储在不同机架节点，用户播放时从就近DataNode获取数据，配合CDN加速提升访问速度。

- **大数据分析原始文件存储**：数据团队需存储10TB的用户行为原始数据，用于离线分析。将文件上传至分布式文件系统，按时间分区存储，分析时通过计算框架并行读取数据块，提升分析效率，同时多副本确保数据不丢失。

- **企业备份文件存储**：某企业需备份1TB的财务数据，要求年度备份且可快速恢复。将备份文件存储在分布式文件系统，设置3副本，定期校验数据完整性，节点故障时可通过副本快速恢复数据，满足备份需求。

### 三、关键决策与方案选型

#### 1. 架构设计核心决策

采用“主从架构”，分为元数据节点（NameNode）和数据节点（DataNode），核心原因：

- **元数据与数据分离**：将文件的元数据（文件名、路径、大小、副本数、数据块位置等）与实际数据分开存储，元数据由NameNode集中管理，数据由DataNode分布式存储，提升管理效率和读写性能；

- **简化架构复杂度**：主从架构职责清晰，NameNode专注于元数据管理，DataNode专注于数据存储和传输，便于开发和维护；

- **适配大文件场景**：大文件按数据块（Block）拆分存储（如128MB/块），DataNode以块为单位管理数据，支持并行读写，提升吞吐。

#### 2. 副本策略选型

采用“3副本存储策略”，而非1副本或2副本，核心考量：

- **可靠性与成本平衡**：1副本存在单点故障风险，2副本在两个节点同时故障时数据丢失，3副本可容忍2个节点故障，同时存储成本可控（相比1副本仅增加2倍成本）；

- **副本放置规则**：第一个副本存放在客户端所在节点（若客户端不在集群内则随机选择），第二个副本存放在与第一个副本不同机架的节点，第三个副本存放在与第二个副本同机架的不同节点，兼顾可靠性和网络传输效率（跨机架传输成本高）。

### 三、核心实现细节

#### 1. 核心组件功能与交互流程

1. **NameNode（元数据节点）**：

2. 核心功能：管理文件系统命名空间（如目录结构、文件属性）、维护数据块映射（文件→数据块→DataNode列表）、记录DataNode状态（通过心跳机制）；

3. 元数据存储：将元数据分为内存存储和磁盘持久化两部分，内存存储所有活跃元数据（确保查询快速），磁盘通过FsImage（元数据快照）和EditLog（操作日志）持久化，避免内存数据丢失；

4. 高可用优化：部署主从两个NameNode，主节点对外提供服务，从节点通过实时同步EditLog保持元数据一致，主节点故障时从节点可快速切换（通过Zookeeper实现自动故障转移）。

5. **DataNode（数据节点）**：

6. 核心功能：存储实际数据块、响应客户端的读写请求、向NameNode汇报心跳（每3秒）和数据块信息（每1小时）；

7. 数据块管理：将数据块存储在本地磁盘，每个数据块对应两个文件（数据文件和校验和文件），校验和文件用于验证数据完整性，避免数据损坏；

8. 数据均衡：当部分DataNode存储容量过高或过低时，NameNode触发数据均衡策略，将数据块迁移至负载均衡的节点，确保集群存储资源高效利用。

9. **文件写入流程**：

10. 客户端向NameNode发起文件创建请求，NameNode检查权限和存储空间后返回可写入的DataNode列表（按副本放置规则选择）；

11. 客户端将文件拆分为数据块（如128MB/块），按顺序向第一个DataNode写入数据，数据通过“流水线复制”方式同步至其他副本节点；

12. 所有副本节点写入完成后，向客户端返回成功响应，客户端通知NameNode更新元数据；

13. 文件读取流程：客户端向NameNode请求文件的数据块位置，NameNode返回距离最近的DataNode列表，客户端直接从DataNode读取数据块并拼接为完整文件。

#### 2. 容错机制设计

- **DataNode故障处理**：

- 故障检测：NameNode若超过10分钟未收到DataNode的心跳，判定该节点故障，将其标记为“死亡”；

- 副本恢复：NameNode检查该节点上的数据块，对副本数不足3的块，调度其他DataNode复制数据，补充副本至3个；

- 数据块清理：故障节点恢复后，NameNode对比其数据块与集群元数据，删除无效数据块（如已被删除的文件块），同步缺失的数据块。

- **数据损坏处理**：

- 损坏检测：客户端读取数据块时验证校验和，若发现校验和不匹配，向NameNode报告数据块损坏；

- 损坏恢复：NameNode标记该数据块为“损坏”，调度从其他副本节点复制数据块至健康DataNode，同时删除损坏的数据块；

- 定期巡检：DataNode定期自检本地数据块的校验和，主动向NameNode报告损坏情况，实现提前修复。

## 3.3 设计一个支持高并发读写的用户数据库（如百万 TPS 场景）

### 一、核心需求解析

- **高并发读**：用户信息查询场景（如登录验证、个人资料查询）占比90%以上，需支持百万级读QPS，响应时间控制在10ms以内。

- **低并发写**：用户信息修改（如修改密码、更新头像）场景较少，写QPS在万级以内，但需保证写操作的原子性和数据一致性。

- **数据一致性**：用户数据的读写需满足“最终一致性”，特殊场景（如余额修改）需满足“强一致性”，避免用户信息错乱。

- **水平扩展**：随着用户量增长（如从千万级到亿级），系统需支持通过增加节点扩展存储和处理能力，扩展过程不中断服务。

### 二、使用用例

- **用户登录验证**：社交APP日活1000万，用户登录时需查询账号密码和权限信息，读QPS达50万。采用“主从分离+二级缓存”架构，读请求路由至10个从库和Redis集群，缓存用户登录信息，响应时间控制在5ms内，支撑高并发登录。

- **用户资料修改**：用户修改头像和昵称，需确保数据实时更新且一致。写请求路由至主库，修改完成后同步更新Redis缓存，通过主从复制同步至从库，确保后续读请求获取最新数据，同时避免缓存与数据库不一致。

- **千万级用户数据查询**：平台有5000万用户，需支持按用户ID快速查询资料。采用按用户ID哈希分库分表（8库16表），单表数据量控制在40万条以内，查询时通过中间件快速定位分库分表，确保查询效率。

### 三、关键决策与方案选型

#### 1. 读写分离策略

采用“一主多从”的读写分离架构，核心逻辑：主库负责所有写操作和部分核心读操作，从库仅负责读操作，通过主从复制同步数据，优势如下：

- **提升读并发**：多从库可分散读请求压力，支持通过增加从库节点线性提升读QPS；

- **降低主库负载**：主库仅处理写操作，避免读操作占用主库资源，提升写操作响应速度；

- **高可用**：主库故障时，可将从库提升为主库，确保服务连续性。

**读写路由**：通过中间件（如MyCat、Sharding-JDBC）实现读写请求自动路由，写请求路由至主库，读请求按负载均衡策略（如轮询、加权轮询）路由至从库；支持强制读主库（如用户修改信息后立即查询）。

#### 2. 分库分表策略

|分片维度|分片规则|优点|缺点|适用场景|
|---|---|---|---|---|
|按用户ID哈希|用户ID哈希后取模（如取模8），分配至不同分库分表|1. 数据分布均匀，避免热点分库；2. 同一用户数据集中，查询效率高；3. 扩展方便（支持一致性哈希）|1. 无法按时间范围归档；2. 跨用户查询需聚合多库数据|用户信息查询、登录验证等按用户ID访问的场景|
|按用户注册时间|按用户注册月份/季度分片（如2025年12月注册用户存至sh_202512）|1. 便于按时间归档历史数据；2. 冷热数据分离，可优化存储成本|1. 数据分布可能不均（如促销期间注册用户激增）；2. 老用户查询需定位历史分库|用户增长分析、历史数据统计场景|
**最终选型**：采用“按用户ID哈希”的分库分表策略，分库数8个，每个分库分16张表，共128张表，单表数据量控制在1000万条以内，确保查询性能。

### 三、核心实现细节

#### 1. 缓存架构与防护机制

采用“Redis集群+本地缓存”的二级缓存架构，缓存用户高频访问数据（如用户ID、用户名、头像、权限信息），提升读性能，同时设计完善的缓存防护机制：

- **缓存穿透防护**：

- 原因：查询不存在的用户ID（如恶意攻击），缓存和数据库均无数据，导致请求直接穿透至数据库，压垮数据库；

- 方案：1. 对不存在的用户ID，在Redis中缓存空值（设置较短过期时间，如5分钟）；2. 前端请求校验用户ID格式，过滤无效ID；3. 部署布隆过滤器，提前拦截不存在的用户ID请求。

- **缓存击穿防护**：

- 原因：热点用户（如千万级粉丝的网红）缓存过期瞬间，大量请求穿透至数据库；

- 方案：1. 热点用户缓存设置永不过期，通过后台异步更新缓存；2. 缓存过期时，使用分布式锁（如Redis SETNX）控制仅一个请求去数据库查询并更新缓存，其他请求等待重试。

- **缓存雪崩防护**：

- 原因：大量缓存同时过期，导致大量请求穿透至数据库；

- 方案：1. 缓存过期时间添加随机值（如基础过期时间30分钟+随机0-5分钟），避免缓存集中过期；2. Redis集群部署，避免单节点故障导致缓存全量失效；3. 数据库部署读写分离和分库分表，提升抗冲击能力。

#### 2. 数据同步与一致性保障

- **主从复制策略**：

- 采用MySQL半同步复制，主库执行写操作后，需等待至少一个从库确认接收二进制日志（binlog）后才返回成功响应，避免主库故障导致数据丢失；

- 从库通过IO线程读取主库的binlog，写入本地中继日志（relay log），再通过SQL线程执行中继日志，同步数据至从库；优化SQL线程为多线程，提升从库同步速度，减少主从延迟。

- **强一致性场景处理**：

- 对于用户余额修改等强一致性场景，采用“主库写+主库读”的方式，避免从库延迟导致的查询数据不一致；

- 使用分布式事务（如TCC）确保跨分库操作的一致性，例如用户转账涉及两个分库的余额修改，通过Try-Confirm-Cancel机制确保要么都成功，要么都回滚。

- **主从延迟优化**：

- 监控主从延迟（通过Seconds_Behind_Master指标），当延迟超过阈值（如1秒）时，将读请求路由至主库；

- 减少大事务操作，将大事务拆分为小事务，缩短主库binlog生成时间；

- 从库使用高性能硬件（如SSD硬盘），提升SQL线程执行速度。

# 4. 高并发 / 实时性系统设计

聚焦 “高 QPS、低延迟” 约束，核心解决“流量扛得住、响应速度快、服务不中断”的问题，同时保障业务逻辑的正确性（如无超卖、消息不丢失）。

## 4.1 设计一个秒杀系统（如电商双十一秒杀）

### 一、核心需求解析

- **高并发支撑**：支持10万QPS的瞬时请求峰值，秒杀活动开始后1秒内完成大量订单创建，系统不宕机、不卡顿。

- **无超卖**：秒杀商品库存有限（如100件），需严格控制订单数量不超过库存，这是秒杀系统的核心业务底线。

- **低延迟**：用户从点击“秒杀”到收到“秒杀结果”的响应时间控制在500ms以内，避免用户因等待过长放弃操作。

- **防刷**：拦截恶意抢购行为（如使用脚本、多账号抢购），确保秒杀公平性，避免正常用户无法抢购。

### 二、使用用例

- **电商双十一秒杀**：某品牌推出1000台特价手机秒杀，活动开始后10秒内有50万用户参与。通过“前端验证码+Nginx限流+Redis预扣减+Kafka缓冲”架构，拦截90%无效请求，仅将1万条有效请求传入订单系统，确保无超卖且系统稳定。

- **限量优惠券抢购**：平台发放1万张满减优惠券，用户需在指定时间抢购。采用Redis分布式锁控制优惠券发放，用户抢购时获取锁并扣减库存，释放锁后生成优惠券，配合黑名单机制拦截脚本抢购，保障公平性。

- **新品首发抢购**：某美妆品牌新品首发，库存5000件，需支持微信、APP、网页多端抢购。通过统一接入层接收多端请求，路由至秒杀服务集群，采用Redis集群存储库存，确保多端库存一致，抢购结果实时同步至各端。

### 三、关键决策与方案选型

#### 1. 流量削峰策略

核心思路：通过“前端-接入层-服务层”三级削峰，将瞬时高流量转化为平稳流量，避免直接冲击核心数据库，关键方案：

- **前端削峰**：

- 按钮置灰：秒杀未开始时按钮置灰，禁止提前点击；

- 验证码/倒计时：秒杀开始前要求用户输入验证码或等待倒计时结束，分散请求发送时间；

- 本地限流：限制单个用户单位时间内的请求次数（如10秒内最多3次），避免单个用户发送大量请求。

- **接入层削峰**：

- CDN静态化：将秒杀活动页面静态资源（图片、CSS、JS）部署至CDN，避免请求穿透至应用服务器；

- Nginx限流：通过nginx的limit_req模块限制单IP请求速率（如每秒10次），直接拦截超量请求，返回“系统繁忙”。

- **服务层削峰**：

- 队列缓冲：使用Redis List或Kafka作为请求队列，应用服务器将秒杀请求写入队列后立即返回“排队中”，由后台消费者按库存数量匀速处理队列中的请求，实现“削峰填谷”。

#### 2. 库存控制策略

采用“Redis预扣减+MySQL最终确认”的双重库存控制策略，确保无超卖，核心逻辑：

- **Redis预扣减**：秒杀活动开始前，将商品库存同步至Redis（如SET seckill:stock:1001 100），用户秒杀时先执行DECR命令预扣减库存，若返回值>=0则预扣减成功，否则返回“秒杀失败”；

- **MySQL最终确认**：预扣减成功的请求，由后台消费者异步创建订单并扣减MySQL库存（使用乐观锁：UPDATE seckill_stock SET num=num-1 WHERE id=? AND num>0），确保库存最终准确；

- **库存校验**：定期对比Redis与MySQL库存，发现差异时及时校准，避免Redis异常导致的库存偏差。

### 三、核心实现细节

#### 1. 秒杀核心流程（高并发优化版）

1. **活动预热阶段（秒杀前1小时）**：

2. 缓存预热：将秒杀商品信息（名称、价格、图片）和库存数量同步至Redis集群，设置商品详情页缓存（过期时间1小时）；

3. 服务扩容：基于预估流量，将秒杀服务、Redis集群、数据库从库扩容至目标节点数（如秒杀服务扩容至20个节点）；

4. 限流配置：配置Nginx、应用服务器的限流规则，部署布隆过滤器拦截无效商品ID请求。

5. **秒杀执行阶段（活动开始后）**：

6. 用户请求拦截：前端完成验证码校验后，发送秒杀请求至接入层Nginx，Nginx执行IP限流后将请求转发至秒杀服务；

7. Redis预扣减：秒杀服务接收请求，先查询用户是否已秒杀成功（Redis黑名单过滤，避免重复抢购），再执行Redis DECR命令预扣减库存，预扣减失败则返回“秒杀失败”；

8. 请求入队：预扣减成功的请求，生成秒杀令牌（如UUID），将用户ID、商品ID、令牌写入Kafka队列，返回“秒杀成功，正在创建订单”；

9. 订单创建：订单服务消费Kafka队列消息，使用乐观锁扣减MySQL库存，创建订单（状态为“待支付”），将订单信息写入Redis；

10. 结果查询：用户通过秒杀令牌查询订单状态，订单服务从Redis返回订单信息或支付链接。

11. **活动结束阶段**：

12. 库存清理：将Redis中剩余库存同步至MySQL，标记秒杀活动结束；

13. 订单处理：关闭超时未支付的订单（如15分钟），释放Redis和MySQL库存，将库存重新开放给普通购买渠道；

14. 数据统计：统计秒杀成功率、参与人数、销售额等指标，生成活动报表。

#### 2. 防刷与高可用保障

- **防刷策略**：

- 用户风控：结合用户账号等级、历史购买记录、设备信息（如IMEI）判断是否为恶意用户，高风险用户直接拦截；

- 令牌验证：秒杀请求需携带前端生成的动态令牌（如基于用户ID和时间戳加密），服务端验证令牌有效性，防止脚本伪造请求；

- 黑名单机制：将恶意请求的用户ID或IP加入黑名单，活动期间禁止参与秒杀，活动结束后解除。

- **高可用保障**：

- 服务熔断降级：使用Sentinel或Hystrix监控秒杀服务状态，当错误率超过阈值（如50%）时，触发熔断，返回“系统繁忙，请稍后重试”，避免服务雪崩；

- 多级降级：极端情况下，依次关闭商品详情页推荐、用户积分查询等非核心功能，集中资源保障秒杀核心流程；

- 故障恢复：Redis集群部署主从+哨兵架构，单个节点故障时自动切换；数据库部署主从架构，主库故障时从库秒级提升为主库，确保服务连续性。

## 4.2 设计一个实时聊天系统（如微信简化版）

### 一、核心需求解析

- **一对一聊天**：支持两个用户之间的实时消息收发，消息延迟控制在1秒以内，支持文本、图片、表情等消息类型。

- **群聊**：支持多人群聊（如500人、2000人群），群消息需快速同步至所有在线成员，避免消息丢失或顺序错乱。

- **消息实时送达**：在线用户需立即收到消息通知，支持消息已读/未读状态同步，提升用户体验。

- **离线消息同步**：用户离线后再次登录，需快速同步期间收到的所有消息，支持按时间范围拉取历史消息。

### 二、使用用例

- **好友一对一聊天**：用户A与用户B实时聊天，发送文本、图片消息，需确保消息延迟低于1秒且不丢失。通过WebSocket建立持久连接，消息经路由服务推送至对方客户端，在线时实时送达，离线时存储至Redis未读列表，上线后同步。

- **500人群聊互动**：公司部门群有500人，用户C发送会议通知，需快速同步至所有在线成员。采用群消息广播机制，路由服务将消息推送至所有在线成员的网关节点，通过分片推送提升效率，确保3秒内所有在线用户收到消息。

- **离线消息同步**：用户D出差期间离线8小时，期间收到20条消息，上线后需快速同步。客户端登录时请求离线消息，服务从Redis和MySQL合并消息，分页返回给客户端，确保消息完整且同步耗时低于2秒。

### 三、关键决策与方案选型

#### 1. 通信协议选型

采用WebSocket协议作为实时通信核心协议，而非传统的HTTP轮询或长轮询，核心优势：

- **全双工通信**：客户端与服务器建立持久连接后，双方可双向实时发送数据，无需频繁建立连接，降低延迟；

- **低开销**：连接建立后仅传输消息数据，头部开销小（相比HTTP轮询减少大量重复头部信息）；

- **跨平台支持**：主流浏览器和移动APP均支持WebSocket，开发成本低。

**降级策略**：对于不支持WebSocket的老旧设备，降级为长轮询（Long Polling），确保消息可达性。

#### 2. 消息存储策略

采用“Redis+MySQL”的混合存储策略，区分消息的实时性和持久性需求：

- **Redis**：存储在线用户的未读消息（如一对一聊天的未读消息列表、群聊的最新消息）、用户在线状态（如使用Redis Hash存储用户ID与连接节点的映射），支持毫秒级读写，满足实时性需求；

- **MySQL**：存储所有消息的历史记录（按用户会话或群聊ID分表），支持消息长期存储和历史查询，作为Redis的兜底存储；

- **对象存储**：图片、文件等大体积消息，MySQL仅存储文件URL，实际文件存储在OSS等对象存储服务中，配合CDN加速下载。

### 三、核心实现细节

#### 1. 系统架构与核心组件

采用“接入层-业务层-存储层”三级架构，核心组件包括：WebSocket网关、用户状态服务、消息路由服务、消息存储服务。

1. **WebSocket网关（接入层）**：

2. 核心功能：接收客户端WebSocket连接请求，建立持久连接，转发消息至业务层；支持连接心跳检测（每30秒），判断用户在线状态；

3. 负载均衡：采用一致性哈希算法将用户连接分配至不同网关节点，确保同一用户的连接始终落在同一节点，便于消息推送；

4. 连接迁移：网关节点故障时，将用户连接平滑迁移至其他节点，通过用户状态服务同步连接信息。

5. **业务层（核心服务）**：

6. 用户状态服务：维护用户在线/离线状态，通过Redis存储“用户ID-网关节点-连接ID”映射，支持实时查询用户状态；

7. 消息路由服务：接收网关转发的消息，解析消息目标（如接收用户ID、群聊ID），查询目标用户的在线状态，将消息路由至对应网关节点；群聊消息采用“广播+订阅”模式，路由至所有在线群成员的网关节点；

8. 消息存储服务：异步将消息写入Redis（未读消息）和MySQL（历史记录），支持消息已读状态更新（如用户读取消息后，删除Redis中的未读消息，更新MySQL消息状态）。

9. **存储层**：

10. Redis集群：部署主从架构，主库存储用户状态和未读消息，从库提供读写分离，提升查询性能；

11. MySQL分表：按“会话ID”分表，一对一聊天的会话ID为“用户AID_用户BID”（按字典序排序，避免重复），群聊的会话ID为“group_群ID”，单表数据量控制在500万条以内；

12. OSS对象存储：存储图片、文件等大消息，生成带签名的临时URL供客户端下载，保障文件安全。

#### 2. 核心业务流程实现

- **一对一聊天流程**：

- 用户A发送消息给用户B：用户A的客户端通过WebSocket连接发送消息至网关，消息包含发送者ID、接收者ID、消息内容、消息类型；

- 消息路由：网关将消息转发至消息路由服务，服务查询用户B的在线状态（通过用户状态服务）；

- 在线推送：若用户B在线，路由服务将消息转发至用户B所在的网关节点，网关通过WebSocket连接推送消息至用户B的客户端，用户B客户端接收后返回“已送达”确认；

- 离线存储：若用户B离线，消息路由服务将消息写入Redis的用户B未读消息列表（键为“unread:user:BID”），同时异步写入MySQL历史记录；

- 已读处理：用户B读取消息后，发送“已读”确认，服务删除Redis中对应的未读消息，更新MySQL消息的“已读状态”。

- **群聊优化流程**：

- 群消息广播：用户发送群消息后，消息路由服务获取群成员列表，过滤在线成员，将消息批量路由至对应网关节点，避免单条消息多次路由；

- 消息分片：对于2000人以上的大型群，将群成员列表分片，由多个线程并行推送消息，提升广播效率；

- 群消息缓存：将群聊最新100条消息存储在Redis（键为“group:msg:群ID”），用户进入群聊时先从Redis获取最新消息，历史消息从MySQL分页拉取。

- **离线消息同步流程**：

- 用户登录：用户登录时，客户端发送“同步离线消息”请求，携带最后一次同步的消息时间戳；

- 消息拉取：服务查询Redis中该用户的未读消息列表，同时从MySQL查询时间戳之后的历史消息，合并去重后返回给客户端；

- 分页同步：若离线消息数量过多（如超过100条），采用分页同步策略，客户端按页拉取，避免单次传输数据量过大导致卡顿。

# 5. MSRA ObjectStore团队高频系统设计项目

该团队核心围绕分布式存储系统构建，聚焦“高吞吐、低延迟、强一致”的分布式哈希表（DHT）设计，以下项目紧密贴合其业务场景与技术栈要求，是面试高频考察方向。

## 5.1 设计一个分布式哈希表（DHT）系统（ObjectStore核心场景）

### 一、核心需求解析（贴合职位Responsibilities）

- **海量数据存储**：支持PB级键值数据存储，单键值对大小从KB级到GB级（覆盖Azure、Office等多业务场景），数据分布均匀无热点。

- **亚毫秒级延迟**：读请求延迟≤1ms，写请求延迟≤5ms，支撑全球数十万机器节点的并发访问（符合职位“sub-millisecond latency”要求）。

- **高可用与容错**：节点故障（机器宕机、网络分区）后，数据不丢失且服务中断时间≤100ms，通过多副本与故障自动转移保障可用性。

- **水平扩展**：支持动态增删节点，扩展过程中数据自动重分布，不影响业务读写，扩展后性能线性提升。

- **数据一致性**：支持“最终一致性”与“强一致性”两种模式切换，满足Azure金融级业务与Office普通业务的不同需求。

### 二、使用用例（贴合团队业务场景）

- **Azure云存储元数据管理**：Azure需存储亿级文件的元数据（文件名、存储路径、权限信息等），要求读延迟≤500μs。基于DHT系统，将元数据键（文件唯一ID）哈希映射至全球节点，通过“本地缓存+主副本”架构，用户读取时先查本地节点缓存，未命中则路由至主副本节点，确保低延迟；主副本故障时，从副本100ms内接管服务。

- **SharePoint文档版本存储**：SharePoint用户频繁修改文档，需存储多版本内容（每个版本对应唯一键），要求写操作原子性且版本不丢失。DHT系统采用“预写日志（WAL）+多副本同步”机制，写请求先写入本地WAL，再同步至2个副本节点，所有节点确认后返回成功，确保版本数据一致；查询历史版本时，通过键后缀（如doc123_v2）快速定位数据。

- **Bing搜索结果缓存**：Bing将高频搜索结果缓存至DHT，需支持每秒百万级读请求与动态节点扩展。采用“一致性哈希+虚拟节点”策略，搜索结果键（查询关键词哈希）映射至虚拟节点，再关联物理节点；新增节点时仅需迁移部分虚拟节点数据，避免全量重分布，扩展后读吞吐提升至原有1.8倍。

### 三、关键决策与方案选型（聚焦职位技术栈）

#### 1. 哈希与分片策略：一致性哈希 vs 范围分片

|策略类型|核心逻辑|优点|缺点|选型结论|
|---|---|---|---|---|
|一致性哈希|将节点与键映射至2^32哈希环，键顺时针关联最近节点；引入虚拟节点（每个物理节点对应100个虚拟节点）解决数据分布不均|1. 节点增删仅影响哈希环上相邻节点，数据迁移量小；2. 支持全球分布式部署，节点地理位置无关；3. 适配ObjectStore“数十万机器”场景|1. 范围查询效率低；2. 热点键无法主动迁移<br>核心选型，贴合团队全球分布式节点场景，配合热点检测机制弥补缺陷||
|范围分片|按键的字典序划分连续范围，每个范围对应一个节点，如键a-f对应节点1，g-l对应节点2|1. 范围查询高效；2. 可主动将热点范围拆分|1. 节点增删需重分布大量数据；2. 全球节点部署时路由复杂<br>仅作为子模块，用于需要范围查询的业务（如SharePoint文档按创建时间查询）||
#### 2. 存储引擎选型：RocksDB定制 vs 自研存储结构

结合职位“Preferred Qualifications”中“RocksDB/LevelDB经验”要求，核心选型为**定制化RocksDB**，优化方向如下：

- **写入优化**：针对ObjectStore大键值场景，调整RocksDB的write buffer大小（从默认64MB增至512MB），减少Level 0到Level 1的压缩次数；引入“延迟压缩”机制，非热点数据在写入10分钟后再执行压缩，提升写入吞吐。

- **读取优化**：启用RocksDB的block cache与index cache分离配置，block cache缓存数据块（占内存80%），index cache缓存索引（占20%）；针对Azure元数据等小键值场景，开启prefix bloom filter，减少磁盘IO次数。

- **高可用增强**：默认RocksDB仅本地存储，扩展为“本地RocksDB+远程副本”模式，本地数据写入后异步同步至远程节点，支持故障时从远程副本快速恢复。

对于核心敏感业务（如Azure金融数据），采用“RocksDB+自研一致性层”方案，确保数据写入的原子性与持久性。

### 三、核心实现细节（融入C++高性能开发要求）

#### 1. 分布式节点通信架构

采用“ gossip协议+grpc”混合通信，兼顾节点状态同步与数据传输效率，核心用C++实现以保障高性能：

- **节点发现与状态同步**：通过gossip协议，每个节点每100ms向随机3个节点广播自身状态（负载、健康度、数据范围），确保全集群状态一致；状态数据采用protobuf序列化，减少传输开销。

- **数据读写通信**：采用grpc的同步流式RPC（streaming RPC），读请求通过“管道化”方式批量获取数据（如一次获取10个键值对），减少TCP连接建立次数；写请求采用异步RPC，客户端发送后无需等待立即返回，服务端通过回调确认写入结果。

- **网络优化**：开启TCP拥塞控制（BBR算法），根据网络带宽动态调整传输速率；针对跨地域节点，采用“就近路由”策略，通过DNS解析获取距离最近的节点IP，降低跨地域延迟。

#### 2. 数据一致性与容错机制

- **多副本策略**：采用“主-从-从”三副本架构，主副本负责读写，两个从副本异步同步数据；副本分布在不同机架（Rack），避免单机架故障导致数据丢失，符合Azure高可用要求。

- **一致性模式切换**：

- 强一致性：写请求需等待主副本与至少一个从副本写入完成后返回，适用于金融级业务；通过C++实现原子操作（std::atomic）确保副本同步状态的准确性。

- 最终一致性：写请求仅主副本完成即可返回，从副本后台同步，适用于普通业务（如Office文档）；同步延迟控制在1s内，通过定时校验机制解决数据不一致。

- **故障检测与恢复**：

- 故障检测：节点间通过心跳（每50ms）检测健康状态，连续3次未响应则判定为故障；结合gossip协议快速扩散故障信息。

- 主副本故障：从副本通过“领导者选举”（基于Raft协议简化版）在100ms内选出新主；选举过程中，客户端请求自动路由至候选从副本，确保服务不中断。

- 数据恢复：故障节点重启后，通过“增量同步”从主副本获取故障期间的增量数据（基于WAL日志偏移量），避免全量同步，恢复时间≤30s。

#### 3. C++高性能优化实践（贴合职位C++经验要求）

- **内存管理优化**：自定义内存池（基于tcmalloc），预先分配固定大小的内存块（如4KB、64KB、1MB），用于存储不同大小的键值对，避免频繁调用malloc/free导致的内存碎片；内存池支持内存复用，提升内存利用率至90%以上。

- **并发控制优化**：采用“细粒度锁”策略，将RocksDB实例按列族（Column Family）拆分，每个列族独立加锁，而非全局锁；对于热点键，引入无锁队列（基于CAS操作）缓存读写请求，减少锁竞争。

- **编译与指令优化**：使用Clang 14编译，开启-O3优化选项；针对x86架构，启用AVX2指令集，对批量数据的哈希计算、序列化等操作进行向量优化，提升计算效率30%以上。

## 5.2 设计一个RocksDB分布式优化层（团队核心技术方向）

### 一、核心需求解析（贴合职位“storage data structures”要求）

- **分布式能力增强**：为单机RocksDB添加分布式协同能力，支持多节点共享数据，解决单机存储容量与并发瓶颈。

- **性能损耗可控**：分布式优化层引入的额外延迟≤100μs，不影响RocksDB原生的高吞吐特性（要求写入吞吐≥10万QPS）。

- **数据分片与聚合**：支持按键哈希分片存储至多个RocksDB实例，查询时自动聚合多实例结果，对上层业务透明。

- **故障隔离**：单个RocksDB实例故障不影响其他实例，支持故障实例的热重启与数据恢复。

### 二、使用用例（贴合团队业务）

- **ObjectStore键值存储扩展**：原单机RocksDB无法满足PB级存储需求，通过分布式优化层将数据按键哈希分片至10个RocksDB节点，每个节点存储100TB数据；上层业务写入键“obj123”时，优化层自动路由至节点3，读取时无需感知分片逻辑，性能损耗仅50μs。

- **Office文档元数据索引**：Office需为亿级文档建立元数据索引（基于RocksDB），支持按文档ID、创建者、时间多维度查询。分布式优化层按文档ID分片，同时维护全局二级索引（存储在Redis），查询“用户A的文档”时，先从Redis获取相关文档ID列表，再路由至对应RocksDB节点查询详情，查询延迟≤800μs。

### 三、关键决策与方案选型

#### 1. 分片架构：代理模式（Proxy）vs 客户端库模式（Client Library）

|架构类型|核心逻辑|优点|缺点|选型结论|
|---|---|---|---|---|
|代理模式|部署独立Proxy节点，接收业务请求后路由至后端RocksDB节点，完成数据分片与聚合|1. 业务无侵入，无需修改代码；2. 集中管理分片策略，便于动态调整；3. 支持故障自动切换|1. Proxy可能成为性能瓶颈；2. 增加网络跳转延迟<br>核心选型，通过Proxy集群（10个节点）负载均衡解决瓶颈，配合共享内存优化本地节点延迟||
|客户端库模式|提供C++客户端库，业务集成后直接与RocksDB节点通信，自主完成路由|1. 无Proxy瓶颈，性能损耗低；2. 网络跳转少|1. 业务侵入性强，需修改代码；2. 分片策略升级复杂|备选方案，仅用于对延迟极致敏感的核心业务|
### 三、核心实现细节（聚焦RocksDB优化）

#### 1. 分布式Proxy核心模块（C++实现）

- **分片路由模块**：基于MurmurHash3算法计算键的哈希值，对分片数取模得到目标节点；支持动态分片（新增节点时自动调整分片映射），通过ZooKeeper维护分片元数据。

- **请求聚合模块**：处理范围查询（如Scan）时，并行向多个RocksDB节点发送子请求，收集结果后按键排序聚合；采用线程池（std::thread_pool）管理并行任务，聚合延迟≤200μs。

- **缓存加速模块**：在Proxy层引入LRU缓存（大小10GB），缓存热点键值对（如最近10分钟访问≥100次的键）；缓存命中时直接返回结果，无需请求后端RocksDB，提升读性能50%。

#### 2. RocksDB节点协同优化

- **WAL日志协同**：每个RocksDB节点的WAL日志异步同步至共享存储（如Azure Blob），Proxy层维护全局WAL索引；故障恢复时，通过全局索引快速定位需要回放的日志，缩短恢复时间。

- **压缩策略协同**：Proxy层监控所有RocksDB节点的负载（CPU、IO利用率），当某节点负载≥80%时，暂停其压缩任务，将压缩请求调度至负载较低的节点；压缩完成后同步数据回原节点，避免单节点过载。

- **数据预热机制**：新增RocksDB节点时，Proxy层从其他节点异步迁移热点数据至新节点，迁移过程中通过“读写双活”确保业务无感知；数据预热完成后，逐步将请求路由至新节点，实现平滑扩展。

## 5.3 设计一个分布式文件元数据服务（ObjectStore关联场景）

### 一、核心需求解析（贴合Azure/SharePoint业务）

- **亿级元数据管理**：支持10亿+文件的元数据（路径、大小、创建时间、存储位置、权限等）存储与查询，元数据读写QPS≥50万。

- **强一致性保障**：元数据修改（如重命名、权限变更）需原子性完成，避免多节点查询结果不一致，符合Azure企业级业务要求。

- **层级目录支持**：支持传统文件系统的层级目录结构（如/a/b/c.txt），目录操作（创建、删除、列举）延迟≤1ms。

- **与ObjectStore集成**：元数据中存储文件对应的ObjectStore键值（如对象ID），支持通过元数据快速定位文件在ObjectStore中的存储位置。

### 二、使用用例

- **SharePoint文档管理**：用户创建“项目计划.docx”并保存至“/部门/技术部/2025项目”目录，元数据服务原子性创建文件元数据与目录节点，记录文件对应的ObjectStore对象ID“obj-789”；其他用户访问该路径时，元数据服务快速查询并返回文件元数据与存储位置，支持直接跳转至ObjectStore读取文件内容。

- **Azure Blob元数据查询**：企业用户批量查询“2025年1月”创建的所有Blob文件元数据，元数据服务通过时间索引快速筛选符合条件的元数据记录，关联ObjectStore获取文件大小、存储节点等信息，10万条结果的查询耗时≤500ms。

### 三、关键决策与方案选型

#### 1. 数据模型：基于ZooKeeper的层级模型 vs 基于DHT的扁平模型

|模型类型|核心逻辑|优点|缺点|选型结论|
|---|---|---|---|---|
|ZooKeeper层级模型|将目录与文件映射为ZooKeeper的节点（目录为持久节点，文件为临时有序节点），通过节点路径维护层级关系|1. 原生支持层级结构，目录操作高效；2. 强一致性保障，适合元数据修改；3. 支持Watcher机制，便于实时通知|1. 亿级节点场景下性能下降；2. 写入吞吐量有限（万级QPS）|用于目录结构维护，配合缓存提升性能；文件元数据存储采用DHT模型|
|DHT扁平模型|将文件路径哈希为唯一键，元数据存储在DHT中；目录列举通过前缀查询实现（如/ a/b/* 对应哈希前缀）|1. 亿级数据存储性能稳定；2. 读写吞吐量高（支持50万QPS）|1. 层级目录操作复杂；2. 前缀查询效率低|核心选型，存储文件元数据；目录结构依赖ZooKeeper协同|
### 三、核心实现细节

#### 1. 混合架构实现（ZooKeeper+DHT）

1. **目录结构维护（ZooKeeper）**：

2. 目录节点设计：每个目录对应ZooKeeper的持久节点，节点数据存储该目录下的文件数量、最近修改时间；如“/部门/技术部”对应节点“/dir/部门/技术部”。

3. 目录操作流程：创建目录时，递归创建父目录节点（如创建/a/b需先创建/a）；删除目录时，先检查子节点是否为空，避免误删；通过Watcher机制监控目录变化，实时更新本地缓存。

4. **文件元数据存储（DHT）**：

5. 键设计：将文件路径“/a/b/c.txt”通过SHA-256哈希为64位键，确保唯一性；元数据包含文件大小、ObjectStore对象ID、权限、创建时间等字段。

6. 读写流程：写入元数据时，先在ZooKeeper中更新目录节点的文件数量，再将元数据写入DHT；读取时，直接通过文件路径哈希查询DHT，缓存命中率≥90%。

7. **目录列举优化**：列举“/a/b/”下的文件时，先通过ZooKeeper获取目录节点信息，再通过DHT的前缀查询（哈希前缀为“/a/b/”的哈希值前20位）获取所有文件元数据，结果按文件名排序后返回。

#### 2. 与ObjectStore集成优化

- **元数据-对象关联**：文件元数据中存储“object_id”字段，对应ObjectStore中的键值；上传文件时，先在ObjectStore中创建对象并获取object_id，再将元数据写入DHT，确保关联一致性。

- **冷热数据分离**：最近30天访问的文件元数据缓存至Redis集群，热点元数据（日访问≥100次）缓存至应用本地内存；超过30天的冷数据仅存储在DHT中，通过定期清理缓存节省资源。

- **监控与运维**：部署Prometheus监控元数据服务的QPS、延迟、缓存命中率等指标；通过ELK系统收集日志，针对元数据修改失败、ObjectStore关联异常等场景设置告警，确保服务稳定。

- 消息拉取：服务查询Redis中该用户的未读消息列表，同时从MySQL查询时间戳之后的历史消息，合并去重后返回给客户端；

- 分页同步：若离线消息数量过多（如超过100条），采用分页同步策略，客户端按页拉取，避免单次传输数据量过大导致卡顿。
> （注：文档部分内容可能由 AI 生成）